# 第4章 数字人生成系统实现与测试

## 4.1 系统架构设计

### 4.1.1 总体架构设计思想

数字人生成系统以"输入驱动生成、模型协同推理、自动化质量评估"为核心设计理念，旨在将数字人讲课视频的制作流程从依赖人工逐帧编辑的繁琐作业，转变为由系统自动完成生成与质量验证的闭环工作流。围绕这一目标，系统在架构层面确立了以下三项基本设计原则。

**关注点分离原则。** 系统将用户交互逻辑、业务调度逻辑与模型推理逻辑划分为相互独立的功能层次，各层次之间通过标准化接口协议传递数据，职责边界清晰，任意一层的内部变更均不影响其他层次的正常运行。这一原则保证了系统在面对模型迭代升级或界面功能扩展时具备良好的可维护性与可扩展性。

**异步解耦原则。** 视频生成推理属于计算密集型任务，单次生成耗时从数十秒至数分钟不等。为避免推理过程长期占用网络连接资源并阻塞前端界面响应，系统采用"请求立即返回、任务异步执行、状态定时轮询"的异步处理模式，将推理任务的执行生命周期与HTTP请求的生命周期彻底解耦，确保前端在推理期间的持续可用性。

**质量闭环原则。** 系统将生成质量评估作为完整生成流程中不可缺少的最终环节。每次视频生成完成后，系统自动触发质量评估模块，对输出视频进行多维度量化评分，并将评分结果与参数调整建议一并返回用户，形成"生成—评估—反馈—优化"的持续改进闭环，以数据驱动方式引导生成质量的迭代提升。

依据上述三项原则，系统整体采用**两域分治**的架构思路，将全部功能模块划分为**软件服务域**与**模型推理域**两大功能域。软件服务域负责用户交互与业务编排，涵盖前端交互层与后端服务层；模型推理域负责AI计算，涵盖视频生成子系统（GPT-SoVITS语音合成、Wav2Lip唇形渲染、SadTalker表情动画）与质量评估子系统（bs多任务视频质量评估模型）。两域之间通过后端服务层统一协调，构成"用户操作触发—软件层调度—模型层推理—结果评估回传"的完整处理流程。系统总体架构如图4-1所示。

图4-1　数字人生成系统总体架构图

```
┌──────────────────────────────────────────────────────────────────────┐
│                         数字人生成系统总体架构                          │
│                                                                      │
│ ┌────────────────────────────────────────────────────────────────┐  │
│ │                         软  件  服  务  域                       │  │
│ │                                                                │  │
│ │  ┌──────────────────────────────────────────────────────────┐  │  │
│ │  │                       前端交互层                          │  │  │
│ │  │  ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐    │  │  │
│ │  │  │ 登录控制台│ │ 形象管理  │ │ 声音克隆  │ │ 视频配置  │    │  │  │
│ │  │  └──────────┘ └──────────┘ └──────────┘ └──────────┘    │  │  │
│ │  │  ┌────────────────────────────────────────────────────┐  │  │  │
│ │  │  │               视频列表 / 五维评分结果展示              │  │  │  │
│ │  │  └────────────────────────────────────────────────────┘  │  │  │
│ │  │           Vue 3 · TypeScript · Pinia · Axios              │  │  │
│ │  └────────────────────────┬─────────────────────────────────┘  │  │
│ │            HTTP 请求 ↕ JSON 响应（RESTful，端口 5000）            │  │
│ │  ┌────────────────────────┴─────────────────────────────────┐  │  │
│ │  │                       后端服务层                          │  │  │
│ │  │  ┌───────────┐ ┌───────────┐ ┌──────────────────────┐    │  │  │
│ │  │  │ RESTful   │ │ 并发任务  │ │  三态任务状态机         │    │  │  │
│ │  │  │ 路由调度  │ │ 线程池   │ │  进行中/完成/失败        │    │  │  │
│ │  │  └───────────┘ └───────────┘ └──────────────────────┘    │  │  │
│ │  │       Python · Flask · Flask-CORS · ThreadPoolExecutor    │  │  │
│ │  └──────────────────────────────────────────────────────────┘  │  │
│ └──────────────────────────────┬─────────────────────────────────┘  │
│                      推理调用 ↓  │  ↑ 结果返回                        │
│ ┌──────────────────────────────┴─────────────────────────────────┐  │
│ │                         模  型  推  理  域                       │  │
│ │                                                                │  │
│ │  ┌─────────────────────────────────┐  ┌─────────────────────┐ │  │
│ │  │         视频生成子系统             │  │    质量评估子系统     │ │  │
│ │  │                                 │  │     （bs 模型）      │ │  │
│ │  │  路径A: 用户音频 → Wav2Lip       │  │  多模态特征提取       │ │  │
│ │  │               唇形同步渲染        │  │  Transformer 编码    │ │  │
│ │  │  路径B: 文本 → GPT-SoVITS → WAV  │  │  五维评分输出         │ │  │
│ │  │         WAV → SadTalker          │  │                     │ │  │
│ │  │               表情动画渲染        │  │                     │ │  │
│ │  │               ↓ MP4 ────────────────→                     │ │  │
│ │  └─────────────────────────────────┘  └─────────────────────┘ │  │
│ └────────────────────────────────────────────────────────────────┘  │
└──────────────────────────────────────────────────────────────────────┘
```

---

### 4.1.2 分层结构设计

本节从软件服务层与模型推理层两个维度，逐一阐述各功能模块的设计方案与技术实现，以呈现两域分治思想在模块级别的具体落地方式。

#### 4.1.2.1 软件服务层

软件服务层由前端交互层与后端服务层上下两层构成，负责系统与用户之间的全部交互逻辑，以及面向模型推理域的任务调度与结果管理。其层次结构如下所示：

```
┌────────────────────────────────────────────────────────────┐
│                         软件服务层                           │
│                                                            │
│  ┌──────────────────────────────────────────────────────┐  │
│  │                      前端交互层                        │  │
│  │                                                      │  │
│  │  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌──────────┐   │  │
│  │  │ 登录/   │ │ 数字人  │ │  声音   │ │  视频    │   │  │
│  │  │ 控制台  │ │ 形象管理│ │  克隆   │ │  配置    │   │  │
│  │  └─────────┘ └─────────┘ └─────────┘ └──────────┘   │  │
│  │  ┌─────────┐ ┌─────────────────────────────────────┐ │  │
│  │  │ 高级配置│ │       视频列表 / 评分结果展示           │ │  │
│  │  └─────────┘ └─────────────────────────────────────┘ │  │
│  │        Vue 3 · TypeScript · Pinia · Axios             │  │
│  └──────────────────────────┬───────────────────────────┘  │
│              HTTP 请求 ↕ JSON 响应（RESTful，端口 5000）      │
│  ┌──────────────────────────┴───────────────────────────┐  │
│  │                      后端服务层                        │  │
│  │                                                      │  │
│  │  ┌──────────┐ ┌──────────┐ ┌───────────────────────┐ │  │
│  │  │ RESTful  │ │ 并发任务 │ │    三态任务状态机        │ │  │
│  │  │ 路由调度 │ │  线程池  │ │ 进行中 / 完成 / 失败    │ │  │
│  │  └──────────┘ └──────────┘ └───────────────────────┘ │  │
│  │  ┌────────────────────┐ ┌─────────────────────────┐  │  │
│  │  │   用户目录管理      │ │   异常捕获 / 响应封装     │  │  │
│  │  └────────────────────┘ └─────────────────────────┘  │  │
│  │        Python · Flask · Flask-CORS · ThreadPool       │  │
│  └──────────────────────────────────────────────────────┘  │
└────────────────────────────────────────────────────────────┘
```

**前端交互层**（Frontend Interaction Layer）承担系统与终端用户之间的全部视觉交互职责，覆盖用户登录认证、数字人形象上传与管理、参考声音录制与克隆配置、讲稿文本输入与编辑、视频生成的触发与进度监控，以及历史视频与质量评分的浏览查阅等核心交互场景。前端以组件化视图结构组织功能页面，通过统一封装的HTTP客户端服务模块与后端服务层通信，自身不承担业务逻辑判断或模型调用职责，保证了交互层的轻量化与独立可替换性。

**后端服务层**（Backend Service Layer）是系统的核心控制与调度中枢，以RESTful风格的HTTP服务接口对外提供统一的服务入口。该层负责接收并解析前端请求、维护用户数据目录、管理异步推理任务的生命周期，并以并发任务队列的形式协调多个推理模块的有序执行。通过引入三态任务状态机（"进行中"、"已完成"、"失败"），后端向前端提供可轮询的推理进度反馈，实现了推理任务执行生命周期与HTTP请求生命周期的彻底解耦。

#### 4.1.2.2 模型推理层

模型推理层承载系统的全部AI计算能力，内部划分为**视频生成子系统**与**质量评估子系统**两个功能子系统。二者在执行时序上串联：视频生成子系统负责将文本与人脸图像合成为数字人说话视频，质量评估子系统随后对生成视频进行多维度自动化评分，并将结构化评分结果返回软件服务层。其内部结构如下所示：

```
┌─────────────────────────────────────────────────────────────────┐
│                            模型推理层                              │
│                                                                 │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │                       视频生成子系统                       │   │
│  │                                                         │   │
│  │    路径 A（用户自录音频）         路径 B（参考音频/TTS合成）  │   │
│  │   ┌──────────────────────┐   ┌──────────────────────┐  │   │
│  │   │  用户音频              │   │  讲稿文本              │  │   │
│  │   │       ↓               │   │       ↓               │  │   │
│  │   │  Wav2Lip              │   │  GPT-SoVITS 语音合成    │  │   │
│  │   │  唇形同步渲染           │   │  （文本 → WAV）        │  │   │
│  │   │       ↓               │   │       ↓               │  │   │
│  │   │  MP4 视频文件          │   │  SadTalker            │  │   │
│  │   └─────────┬─────────────┘   │  表情动画渲染           │  │   │
│  │             │                 │       ↓               │  │   │
│  │             │                 │  MP4 视频文件          │  │   │
│  │             │                 └──────────┬────────────┘  │   │
│  └─────────────┼────────────────────────────┼───────────────┘   │
│                │  MP4 视频（两路径汇合输出）  │                    │
│                └──────────────┬─────────────┘                   │
│                               ↓                                  │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │                    质量评估子系统（bs 模型）                 │   │
│  │                                                         │   │
│  │  多模态特征并行提取                                        │   │
│  │  ┌─────────────┐ ┌─────────────┐ ┌────────┐ ┌────────┐  │   │
│  │  │ 视觉深度特征 │ │ 音频语义特征 │ │ 关键点 │ │ AU特征 │  │   │
│  │  └──────┬──────┘ └──────┬──────┘ └───┬────┘ └───┬────┘  │   │
│  │         └───────────────┴────────────┴───────────┘       │   │
│  │                               ↓                          │   │
│  │                 Transformer 跨模态编码器                   │   │
│  │                               ↓                          │   │
│  │  五维评分输出：口型同步 / 表情自然度 / 音频质量 /             │   │
│  │               跨模态一致性 / 综合质量  →  JSON              │   │
│  └─────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────┘
```

**视频生成子系统**集成三个协同工作的深度学习模型，按照音频来源形成两条互斥的串行处理路径。**GPT-SoVITS语音合成模型**（在VITS端到端TTS架构基础上引入GPT语义令牌建模的扩展框架，具备零样本声音克隆能力）接收讲稿文本作为输入，输出自然语音WAV音频文件，支持基于参考音频的零样本声音克隆以还原目标说话人音色。**Wav2Lip唇形同步渲染模型**接收音频文件与参考人脸图像，采用音视频联合判别器训练策略，生成唇形与音频高度同步的数字人视频，适用于唇形同步精度要求较高的应用场景。**SadTalker表情动画渲染模型**以三维面部系数（3DMM）对面部动态进行建模，将音频特征映射为表情系数与姿态系数，经人脸渲染网络输出具有自然表情与头部姿态变化的数字人视频，适用于以TTS合成语音驱动的数字人生成场景。系统依据用户提供的音频配置自动路由：若存在用户自录音频，则进入Wav2Lip处理路径（路径A）；否则进入GPT-SoVITS→SadTalker处理路径（路径B）。

**质量评估子系统**集成了本文提出的bs多任务学习视频质量评估模型。该模型接收生成视频文件，通过视觉深度特征、音频语义特征、面部关键点特征与面部动作单元特征的并行提取，经跨模态Transformer编码器对多模态时序特征进行联合建模，输出结构化的多维度量化评分，为系统质量反馈闭环提供数据支撑。bs模型的完整功能定位与调用机制详见4.1.3节。

系统各功能域的技术选型如表4-1所示。

**表4-1　系统技术选型说明**

| 功能域 | 组件 | 技术选型 | 选型依据 |
|---|---|---|---|
| 软件服务域 | 前端框架 | Vue 3 + TypeScript | 渐进式框架，Composition API提升逻辑复用性；TypeScript增强类型安全 |
| 软件服务域 | 前端状态与路由 | Pinia + Vue Router | 轻量级全局状态管理；多视图路由支持 |
| 软件服务域 | 前端网络通信 | Axios（含拦截器封装） | 支持超长超时配置；统一请求/响应日志；支持Base64文件内联传输 |
| 软件服务域 | 后端服务框架 | Flask + Flask-CORS | 轻量级Python Web框架，低耦合，易于集成推理模型；CORS支持前后端分离部署 |
| 软件服务域 | 并发任务管理 | ThreadPoolExecutor | 适用于计算密集与IO混合型任务；并发数可配置，避免长时推理阻塞主服务线程 |
| 模型推理域 | 语音合成 | GPT-SoVITS | GPT语义令牌建模与SoVITS声码器结合的端到端TTS框架，支持零样本参考音频声音克隆 |
| 模型推理域 | 唇形同步渲染 | Wav2Lip | 音视频联合判别训练，唇形同步精度高，支持任意人脸图像输入 |
| 模型推理域 | 表情动画渲染 | SadTalker | 基于3DMM三维面部系数驱动，头部姿态与表情动画自然 |
| 模型推理域 | 视觉特征提取 | py-feat（RetinaFace + ResNet-101） | 集成人脸检测、关键点定位、AU识别与深层视觉特征提取的一体化工具链 |
| 模型推理域 | 音频特征提取 | HuBERT | 自监督大规模预训练，语音语义表征能力强，适用于跨模态质量评估 |
| 模型推理域 | 关键点检测 | MediaPipe Face Mesh | 实时提取468个三维面部关键点，眼部与唇部区域覆盖完整 |
| 模型推理域 | 质量评估框架 | PyTorch + Transformer | 动态图机制便于模型部署；多头注意力机制建模时序与跨模态依赖 |

---

### 4.1.3 bs模型在系统中的位置与职责

在系统的两域架构中，bs模型隶属于模型推理层的质量评估子系统，位于整个数字人生成管线的末端，是生成结果到达前端用户之前经历的最后一道处理环节。

**位置定位。** bs模型在模型推理层内与视频生成子系统串联，执行时序上严格置于GPT-SoVITS、Wav2Lip、SadTalker三个生成模型之后，构成生成管线的质量验证节点。bs模型由后端服务层在视频渲染任务完成后自动触发调用，其输入为视频生成子系统写出的MP4视频文件，输出为结构化的多维度质量评分数据，二者之间通过共享用户任务目录实现数据传递。

**职责界定。** bs模型在系统中承担三项核心职责：其一，**质量感知**，接收生成视频文件，通过多模态特征提取与跨模态联合评估，从口型同步、表情自然度、音频质量、跨模态一致性与综合质量五个维度输出量化评分；其二，**结果持久化**，将评分结果以结构化JSON格式写入用户任务目录，与视频文件并列存储，供后续检索与前端展示调用；其三，**反馈驱动**，评分结果经由后端服务层随视频数据一并下发前端，前端依据各维度分值生成差异化的参数优化建议，形成数据驱动的生成质量改进闭环。

**调用流程。** 后端服务层在接收到视频生成子系统任务完成的通知后，向质量评估子系统（bs模型）发起调用，传入已写出的视频文件路径；bs模型依次执行视频解码、多模态特征提取与Transformer前向推理，生成五维评分字典；后端将评分数据与视频文件路径信息整合，在前端发起视频拉取请求时一并响应，完成质量信息的完整闭环传递。整个调用过程对用户透明，无需手动干预。

---

### 4.1.4 系统数据流转路径

系统的数据流转路径构成一条从用户输入到质量反馈的完整闭合链路，可划分为**请求下行路径**、**推理处理路径**与**结果上行路径**三个阶段，如图4-2所示。

图4-2　数字人生成系统数据流转路径示意图

```
                        用户（前端操作）
                               │
                               ▼
              ╔════════════════════════════════════════╗
              ║           第一阶段：请求下行路径           ║
              ║                                        ║
              ║  前端封装 HTTP 请求                      ║
              ║  （文本 / 图像 / 音频 / 参数配置）         ║
              ║              ↓                         ║
              ║  后端接收 → 解析参数 → 初始化任务目录      ║
              ║  → 异步路由，立即返回任务标识（不阻塞）      ║
              ╚══════════════════╤═════════════════════╝
                                 │
                        ┌────────┴─────────┐
                        │   音频来源判断     │
                        └────┬────────┬────┘
               用户自录音频   │        │  参考音频 / 无音频
                             ↓        ↓
                          Wav2Lip   GPT-SoVITS 语音合成
                         唇形同步渲染  WAV → SadTalker
                             │         表情动画渲染
                             └────┬─────┘
                                  ↓
              ╔════════════════════════════════════════╗
              ║           第二阶段：推理处理路径           ║
              ║                                        ║
              ║  MP4 视频写入用户任务目录                 ║
              ║              ↓ 自动触发                  ║
              ║         bs 质量评估模型                   ║
              ║  多模态特征提取 → Transformer 编码         ║
              ║      → 五维评分 JSON 写入任务目录          ║
              ╚══════════════════╤═════════════════════╝
                                 │
                                 ▼
              ╔════════════════════════════════════════╗
              ║           第三阶段：结果上行路径           ║
              ║                                        ║
              ║  任务状态更新 → "已完成"                   ║
              ║  前端定时轮询 → 检测完成信号               ║
              ║  拉取：MP4 视频文件 + 五维评分 JSON         ║
              ║  渲染：视频播放器 + 评分卡片                ║
              ║  低分维度 → 触发参数优化建议                ║
              ╚══════════════════╤═════════════════════╝
                                 │
                        用户调整参数配置
                                 │
                                 ▼
                        重新触发视频生成
                    （构成质量改进闭环回路）
```


**请求下行路径。** 用户在前端完成数字人形象配置、声音克隆配置与讲稿文本输入后，触发视频生成请求。前端将用户输入数据（包括文本内容、人脸图像、音频文件及模型参数配置）封装为标准化HTTP请求，发送至后端服务层。后端完成请求解析与用户任务目录初始化后，依据用户目录中音频文件的存在状态执行推理路径路由——若存在用户自录音频，则路由至Wav2Lip渲染链路（路径A）；若存在参考音频，则路由至GPT-SoVITS语音合成加SadTalker表情渲染链路（路径B）——并将生成任务提交至异步执行队列，立即向前端返回任务标识，不阻塞请求线程。

**推理处理路径。** 生成任务在后端线程池中异步执行，依次经历语音合成与视频渲染两个子阶段：语音合成阶段（路径B）将文本转换为自然语音，输出WAV格式音频文件；视频渲染阶段将音频与人脸图像融合，输出具有唇形同步与面部表情的数字人MP4视频文件。视频文件写入用户任务目录后，bs模型被自动触发，对视频执行多模态特征提取与质量评分推理，将五维评分数据以JSON格式写入同一任务目录，与视频文件并列存储。

**结果上行路径。** 推理任务全部完成后，后端将任务状态标识更新为"已完成"。前端通过定时轮询状态接口检测到完成信号后，发起视频文件与评分数据的拉取请求；后端从用户任务目录读取相应文件并封装响应返回前端。前端完成视频播放界面与五维评分卡片的渲染，向用户呈现完整的生成结果与质量报告。若某一维度评分低于预设阈值，系统自动展示对应的参数优化建议，引导用户调整配置后重新触发生成，构成完整的质量改进闭环。

---

### 4.1.5 系统部署架构

本系统采用单机一体化部署方案，将前端服务、后端服务及全部推理模型部署于同一台配备高性能GPU的工作站之上。该方案与系统面向个人用户的使用定位相契合，在减少跨网络通信延迟的同时，简化了多组件协同部署的配置复杂度，并使所有推理模型能够充分共享单节点GPU的计算资源。

在服务端口分配上，前端应用服务监听本地5173端口，后端RESTful API服务监听5000端口，两者通过本机回环网络（localhost）进行HTTP通信，无需穿越外部网络路由。各推理模型以Python进程形式常驻于后端服务的执行空间内，服务启动时完成模型权重的一次性预加载，后续推理请求直接调用已加载权重执行前向计算，避免逐次加载开销。

在存储结构上，系统以本地文件系统为各模块之间的数据共享介质。后端服务为每位用户维护独立的任务目录，该目录作为推理链路各阶段的数据交换节点，同时也是前端拉取生成结果的数据来源。用户的参考图像、音频文件、生成视频及质量评分均以文件形式持久化于对应目录下，各推理模块通过读写共享目录中的文件完成数据流转，实现了模块间数据耦合的最小化。系统部署架构如图4-3所示。

图4-3　数字人生成系统部署架构示意图

```
┌─────────────────────────────────────────────────────────────────┐
│                       GPU 工作站（单机部署）                        │
│                                                                 │
│  ┌──────────────────────┐             ┌──────────────────────┐  │
│  │      前端应用区         │             │       后端应用区       │  │
│  │                      │◄── HTTP ───►│                      │  │
│  │  Vue 3 前端服务        │  (localhost) │  Flask 后端服务       │  │
│  │  监听端口 5173          │             │  监听端口 5000         │  │
│  └──────────────────────┘             │                      │  │
│                                       │  ┌──────────────────┐ │  │
│                                       │  │   视频生成子系统   │ │  │
│                                       │  │                  │ │  │
│                                       │  │  GPT-SoVITS 语音合成│ │  │
│                                       │  │  Wav2Lip 渲染     │ │  │
│                                       │  │  SadTalker 渲染   │ │  │
│                                       │  └────────┬─────────┘ │  │
│                                       │           │ MP4        │  │
│                                       │  ┌────────▼─────────┐ │  │
│                                       │  │   质量评估子系统   │ │  │
│                                       │  │    （bs 模型）    │ │  │
│                                       │  └────────┬─────────┘ │  │
│                                       └───────────│────────────┘  │
│                                                   │               │
│                    ┌──────────────────────────────▼─────────┐    │
│                    │        用户任务目录（本地文件系统）          │    │
│                    │  参考图像 │ WAV音频 │ MP4视频 │ 评分JSON │    │
│                    └────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────────┘
```
---

## 4.2 系统实现

本节依照4.1节所确立的两域分治架构，逐模块阐述各功能单元的具体实现方案。模型推理域方面，4.2.1节以"模型驱动数字人视频生成"为主题，统一介绍语音合成与视频渲染两个紧密衔接的子阶段；4.2.2节说明bs模型如何与数字人生成系统衔接，重点阐述视频渲染完成后的质量反馈闭环机制；软件服务域方面，4.2.3节说明前后端交互与推理调度机制。

---

### 4.2.1 模型驱动数字人视频生成

数字人视频生成管线以讲稿文本与参考人脸图像为输入，依次经由语音合成阶段与视频渲染阶段，输出具有自然唇形与面部表情的数字人讲课视频。语音合成阶段基于GPT-SoVITS框架将文本转换为携带目标说话人音色的语音音频；视频渲染阶段则根据音频来源选择对应的渲染模型——Wav2Lip负责唇形同步渲染，SadTalker负责表情动画渲染——将音频与人脸图像合成为最终的MP4视频文件。图4-4展示了该生成管线的整体流程。

图4-4　数字人视频生成管线流程图

```
  用户输入
  ┌────────────────────────────────────────────────────────────┐
  │  讲稿文本（PPT备注，按幻灯片逐页存储于 PPT_Remake.json）         │
  │  参考人脸图像（Image.png）                                    │
  │  参考音频（Ref_Wav.wav）或自录音频（User_Wav.wav）              │
  └────────────────────────────┬───────────────────────────────┘
                               │
                               ▼
  ┌──────────────────────────────────────────────────────────────┐
  │  语音合成阶段（GPT-SoVITS）                                    │
  │  LangSegment分句 → GPT语义令牌生成 → SoVITS声码器合成           │
  │  输出：PPT_Audio/ 目录下的逐页 WAV 文件                         │
  └──────────────────────┬───────────────────────────────────────┘
                         │ 音频文件清单（Audio_save_path.json）
                         ▼
         ┌──────────────────────────────┐
         │  音频来源路由判断              │
         └──────┬────────────────┬──────┘
    User_Wav.wav│存在             │不存在（使用TTS音频）
                ↓                ↓
  ┌─────────────────────┐  ┌──────────────────────────┐
  │  Wav2Lip 唇形渲染   │  │  SadTalker 表情动画渲染   │
  │  （路径A）          │  │  （路径B）                │
  └──────────┬──────────┘  └────────────┬─────────────┘
             └──────────────┬───────────┘
                            ↓
               输出：MP4 视频文件 → 质量评估模块
```

#### 4.2.1.1 语音合成阶段

语音合成模块基于GPT-SoVITS框架构建，属于端到端的文本转语音（TTS）系统，具备零样本声音克隆能力。该框架由GPT语言模型与SoVITS声码器两级模型协同完成推理，前者负责将文本序列转换为语音语义令牌（semantic token），后者负责将语义令牌与参考音频的音色特征融合，最终合成目标语音波形。

**文本预处理与多语言切分。** 在将文本送入GPT语言模型之前，系统调用LangSegment工具对输入文本进行语言检测与分句处理。LangSegment依据Unicode字符范围自动识别中文、英文、日文、韩文等多语言混合文本，将连续的句子按标点符号或预设字数阈值切分为适合单次推理的短句序列，避免过长句子导致注意力机制建模质量下降。切分后的句子列表以迭代方式逐条送入TTS推理流程，各页幻灯片对应的备注文本经此流程生成独立WAV音频文件。

**GPT-SoVITS声音克隆推理。** GPT模型以自回归方式将目标文本的BPE令牌序列与参考音频特征联合编码，逐帧预测语音语义令牌。参考音频作为说话人风格条件注入，使生成的语义令牌携带目标说话人的韵律节奏特征。SoVITS声码器在解码阶段以向量量化（Vector Quantization）方式提取参考音频的音色特征，将语义令牌序列映射至与该音色高度一致的原始PCM音频波形，最终由soundfile库写出为16000Hz单声道WAV文件。系统通过`change_gpt_weights`与`change_sovits_weights`两个函数接口分别热加载GPT和SoVITS的模型权重，支持在运行时切换不同的声音克隆模型，无需重启后端服务。推理时调用`get_tts_wav`函数接口，以生成器形式逐帧输出PCM音频数据，后端代码消费该生成器直至迭代完成，取最后一帧完整音频写入磁盘。

**批量推理与音频管理。** 系统为每张幻灯片的备注文本独立发起一次TTS推理，所有生成的WAV文件按页码序号命名，集中存放于用户任务目录下的`PPT_Audio`子目录。推理完成后，系统遍历该目录并将页码到文件路径的映射以JSON格式写入`Audio_save_path.json`，作为后续渲染模块的音频输入清单。若用户提供了自录音频（`User_Wav.wav`），则跳过TTS环节，直接将自录音频注册至音频清单，沿Wav2Lip渲染路径处理。

#### 4.2.1.2 Wav2Lip唇形同步渲染

Wav2Lip模型通过音视频联合判别器训练策略，在生成阶段强制约束唇形动作与音频节拍的时序对齐。其推理流程分为以下四个环节。

**人脸检测与帧预处理。** 渲染模块首先调用`Change_Video_Fps`方法，将输入视频帧率统一转换为25fps，确保音频帧率与视频帧率的固定比例关系。随后使用RetinaFace检测器（基于MobileNet骨干网络）逐帧检测人脸边界框，并通过预置的dlib predictor提取68个面部关键点，裁剪出嘴唇区域感兴趣区（ROI）。检测结果以pickle格式缓存至用户临时目录，避免多页视频生成时重复执行耗时的人脸检测操作。

**音频特征提取与帧对齐。** 模块将输入音频转换为梅尔频谱（mel-spectrogram），以固定窗口大小对频谱进行分帧，使每一音频帧与对应的视频帧在时间轴上精确对齐，构成音视频帧对作为模型输入。

**Wav2Lip模型前向推理。** 模型以音视频帧对为输入，通过视觉编码器（处理视频帧）与音频编码器（处理mel频谱）分别提取特征，经交叉注意力融合后送入解码器生成覆盖唇部区域的预测帧。预测帧包含修改后的唇形区域，通过高斯混合遮罩（`kernel`与`last_mask`参数控制过渡边界）与原始帧进行自适应融合，消除唇部区域与周围皮肤的色差边界。

**视频合成与输出。** 逐帧推理完成后，模块调用ffmpeg将生成的帧序列与原始音频轨道合并编码为H.264 MP4视频，写入用户Wav2Lip结果目录。每页幻灯片对应独立的视频剪辑，路径映射写入`Video_save_path.json`供后续合成模块读取。

#### 4.2.1.3 SadTalker表情动画渲染

SadTalker基于三维面部变形模型（3DMM）对面部动态进行参数化建模，将音频信号驱动为面部表情系数与头部姿态系数，经人脸渲染网络合成具有真实感的数字人视频。其推理流程分为三个阶段。

**阶段一：预处理与三维系数提取（CropAndExtract）。** 该阶段以参考人脸图像为输入，通过人脸检测模型定位面部区域并裁剪至标准尺寸，随后调用预训练的三维重建网络提取参考人脸的外观系数（包含形状系数、纹理系数、表情系数和相机参数），作为面部重建的静态基准。系数格式与DECA、Deep3DFaceRecon等主流三维人脸重建框架兼容。

**阶段二：音频到三维系数（Audio2Coeff）。** 该阶段以梅尔频谱为输入，通过预训练的映射网络（基于LSTM或Transformer结构）将音频帧序列映射为对应时刻的表情系数增量与头部姿态系数（偏航/俯仰/翻滚），生成随时间变化的三维面部系数序列。表情尺度参数（expression_scale）控制表情幅度，该参数可由用户通过高级配置界面调节，以平衡表情自然度与幅度强度。

**阶段三：三维系数到视频帧（AnimateFromCoeff）。** 该阶段以静态参考帧与逐帧三维系数序列为输入，通过基于流场变形（flow-based warping）的图像渲染网络逐帧合成具有目标面部表情与头部姿态的视频帧，并调用可选的人脸增强模块（GFPGAN或RestoreFormer）提升生成帧的细节清晰度，最终写出MP4视频文件。

---

### 4.2.2 bs模型与数字人生成系统的衔接

bs模型（详见第三章）在本系统中承担在线质量评估职责：数字人视频渲染线程完成后，后端服务自动调用bs模型对生成的MP4视频进行多维度量化评分，评分结果随即通过前端界面反馈给用户，并驱动参数优化建议，形成"生成—评估—建议—调整—再生成"的完整质量改进闭环。其系统集成位置如图4-5所示。

图4-5　bs模型在数字人生成系统中的集成位置

```
  数字人视频生成管线（§4.2.1）
  ┌─────────────────────────────────────────────────────────┐
  │  语音合成（GPT-SoVITS）→ 视频渲染（Wav2Lip / SadTalker）   │
  │                               ↓ MP4 视频文件写入磁盘       │
  └───────────────────────────────┬─────────────────────────┘
                                  │ 触发评估
                                  ▼
  ┌─────────────────────────────────────────────────────────┐
  │  bs 模型自动评估                                          │
  │  evaluate_single_video(video_path)                       │
  │  → 五维评分 {"lip_sync", "expression",                   │
  │              "audio_quality", "cross_modal", "overall"}  │
  └───────────────────────────────┬─────────────────────────┘
                                  │ scores.json 写入任务目录
                                  ▼
  ┌─────────────────────────────────────────────────────────┐
  │  前端质量反馈展示                                          │
  │  · 五维进度条卡片（颜色阈值：绿 ≥4.0 / 黄 3.0–4.0 / 红 <3.0）│
  │  · 低分维度触发参数优化建议                                 │
  │  · 用户调整参数 → 重新触发生成                              │
  └─────────────────────────────────────────────────────────┘
```

视频渲染线程完成后，后端调用 `evaluate_single_video(video_path, checkpoint, config)` 接口触发bs模型推理。bs模型内部完成多模态特征提取与多任务前向推理（架构详见第三章）后，将口型同步、表情自然度、音频质量、跨模态一致性与综合质量五项评分以字典形式返回。后端随即将评分字典序列化为JSON格式，写入用户任务目录的 `scores.json` 文件，与同目录下的MP4视频文件并列存储。当前端调用 `/Pull_Video_Merge` 接口拉取视频时，后端一并将评分数据封装于响应体内返回，前端在视频详情页通过进度条卡片可视化展示五维评分（绿色≥4.0，黄色3.0–4.0，红色<3.0），并针对低于预设阈值的维度自动展示对应的参数优化建议，具体建议规则如表4-2所示。

**表4-2　质量维度低分触发的参数优化建议**

| 质量维度 | 低分阈值 | 系统触发建议 |
|---|---|---|
| 口型同步 | < 3.5 | 建议降低Wav2Lip渲染步长，或切换至SadTalker渲染方案 |
| 表情自然度 | < 3.5 | 建议调小SadTalker的`expression_scale`参数，减少非自然表情幅度 |
| 音频质量 | < 3.5 | 建议重新录制参考音频，或调整VITS语速与音量参数 |
| 跨模态一致性 | < 3.5 | 建议核查输入文本与人脸素材的匹配关系 |
| 综合质量 | ≥ 3.5 | 系统自动将视频标记为有效存档，纳入历史视频列表 |

用户参照建议调整参数配置并重新触发生成，形成完整的质量改进闭环，使视频感知质量在迭代中逐步收敛，综合质量评分趋向3.5分以上的可接受区间。

---

### 4.2.3 前后端交互实现

前后端交互模块是系统各功能环节的通信枢纽，负责协调用户界面操作与后端推理服务之间的数据流转。系统采用RESTful风格的HTTP API实现前后端解耦，前端通过统一封装的HTTP客户端服务层管理所有与后端的通信行为，后端以Flask框架提供服务接口，并通过线程池实现计算密集型任务的异步执行。

#### 4.2.3.1 后端推理调度与路由逻辑

后端服务在接收到推理请求（`POST /Get_Inference`）后，执行以下四步调度逻辑：

**第一步：目录结构初始化。** 后端在文件系统中为当前用户创建标准化的任务目录树，包含`DataBase/<user>/`下的VITS结果目录、SadTalker结果目录、Wav2Lip结果目录及用户数据根目录，清除上次生成的残留文件，确保本次推理拥有干净的工作空间。

**第二步：音频来源路由判断。** 后端检测用户数据目录下`User_Wav.wav`（用户自录音频）与`Ref_Wav.wav`（参考音频）的存在状态，依据以下优先规则路由至对应推理函数：
- 存在`User_Wav.wav` → 调用`User_Wav_Wav2Lip_Inference`（路径A：用户音频+Wav2Lip）；
- 存在`Ref_Wav.wav` → 调用`VITS_Sadtalker_Inference`（路径B：VITS语音合成+SadTalker）；
- 均不存在 → 以内置默认参数执行路径B。

**第三步：任务状态初始化与异步提交。** 路由判断完成后，后端将本次推理任务的状态标记置为"Processing"，随后以`ThreadPoolExecutor.submit()`方式将推理函数提交至并发线程池异步执行，支持同时处理最多5个用户的并行推理请求。线程池提交操作立即返回Future对象，主服务线程无需等待推理完成。

**第四步：立即响应前端。** 后端将任务标识符（如`"Audio_Video_Inference"`）封装为JSON响应立即返回前端，HTTP请求生命周期就此结束，推理任务继续在后台线程中异步执行。推理完成后，后台线程自动调用`Task_State`更新任务状态为`"True"`（成功）或`"False"`（失败）。

#### 4.2.3.2 API接口设计

后端向前端暴露如下核心REST接口，所有接口统一返回含`result`字段的JSON响应：

**表4-3　系统核心API接口说明**

| 接口路径 | 方法 | 功能说明 | 主要参数 |
|---|---|---|---|
| `/Login` | POST | 用户身份验证 | `User`, `Password` |
| `/Send_Image` | POST | 上传数字人形象图片（Base64） | `User`, `Img` |
| `/Send_Config` | POST | 发送模型参数配置 | `User`, `VITS_Config`, `SadTalker_Config` |
| `/Send_Wav2Lip_Config` | POST | 发送Wav2Lip参数配置 | `User`, `Wav2Lip_Config` |
| `/Send_PPT_Remakes` | POST | 上传PPT各页备注文本 | `User`, `PPT_Remakes` |
| `/Upload_PPT_Parse_Remakes` | POST | 上传PPT文件并自动解析备注 | `User`（表单）, `File` |
| `/Send_Video` | POST | 上传参考视频文件 | `User`（表单）, `File` |
| `/Get_Inference` | POST | 触发视频生成推理（智能路由） | `User` |
| `/Get_State` | POST | 查询异步任务执行状态 | `User`, `Task` |
| `/PPT_Video_Merge` | POST | 触发PPT与数字人视频合成 | `User` |
| `/Pull_Video_Merge` | POST | 拉取最终合成视频及评分数据 | `User` |
| `/Cartoonize_Image` | POST | 数字人形象风格化处理 | `User`, `Img`, `Mode`, `Style` |

大体积文件（图片、音频、视频）采用multipart/form-data或Base64编码内联传输两种方式，接口响应值`result`为`"Success"`、`"Failed"`或任务标识符（如`"Audio_Video_Inference"`）。后端通过`log_exceptions`装饰器统一捕获推理端点异常，异常发生时以500状态码返回结构化错误信息，避免服务中断。

#### 4.2.3.3 前端HTTP服务层设计

前端基于Axios封装统一的API服务层，具备以下设计特点：

**超长超时配置。** 视频生成推理通常耗时数分钟至数十分钟，HTTP请求超时时间配置为1小时（3600秒），视频上传接口超时延长至2小时，防止前端因超时而误判推理失败。

**请求/响应拦截器。** 在调试模式下自动记录每次请求的方法、路径、耗时与响应状态，便于开发阶段的接口联调与性能分析。

**统一错误处理。** 当响应`result`字段为`"Failed"`时，服务层抛出统一异常，由调用方依据业务语义展示错误提示，保证错误处理逻辑集中管理。

**环境适配配置。** 后端服务地址通过外部配置注入，支持开发、测试与生产环境的灵活切换，默认指向本机5000端口。

#### 4.2.3.4 异步任务状态轮询机制

由于视频推理属于耗时计算任务，系统采用"请求立即返回+异步执行+定时轮询"的处理模式。其交互时序如图4-8所示。

图4-8　异步任务轮询时序图

```
  前端                         后端服务                      推理线程池
    │                              │                              │
    │── POST /Get_Inference ──────►│                              │
    │                              │── submit(推理任务) ──────────►│
    │◄── {"result":"Audio_Video_   │                              │ （异步执行中）
    │      _Inference"}────────────│                              │
    │                              │                              │
    │（弹出进度遮罩，开始轮询）         │                              │
    │── POST /Get_State ──────────►│                              │
    │◄── {"result":"Processing"} ──│                              │
    │         │（等待10s）           │                              │
    │── POST /Get_State ──────────►│                              │
    │◄── {"result":"Processing"} ──│                              │
    │         │（等待10s）           │                 ┌────────────┘
    │                              │◄─ Task_State("True") ───────│
    │── POST /Get_State ──────────►│                              │
    │◄── {"result":"True"} ────────│                              │
    │                              │                              │
    │（关闭进度遮罩）                  │                              │
    │── POST /Pull_Video_Merge ───►│                              │
    │◄── {视频URL + 评分JSON} ───────│                              │
```

前端收到推理触发响应后弹出进度遮罩，以固定间隔（默认10秒）轮询`/Get_State`接口，直至收到`"True"`响应后关闭遮罩并调用视频拉取接口获取最终结果。轮询设有超时保护（默认30分钟），超时后自动标记任务为失败状态并提示用户重试。

#### 4.2.3.5 前端视图与组件设计

前端基于Vue 3的Composition API以组件化方式组织视图逻辑，采用Vue Router管理多页面路由，以Pinia进行跨组件状态共享。核心视图与组件的职责划分如表4-4所示：

**表4-4　前端核心视图与组件说明**

| 视图/组件 | 层级 | 功能说明 |
|---|---|---|
| 登录页（LoginView） | 视图 | 账号密码验证，通过后跳转至控制台 |
| 控制台（DashboardView） | 视图 | 汇总各功能入口，展示系统整体状态 |
| 视频生成页（VideoConfigView） | 视图 | 集成视频生成全流程的步骤式操作界面 |
| 视频列表页（VideoListView） | 视图 | 展示历史生成视频，支持在线播放与下载 |
| 数字人管理页（PersonManagerView） | 视图 | 数字人形象图片的上传与管理 |
| 声音训练页（VoiceTrainerView） | 视图 | 参考音频采集、上传与声音克隆训练触发 |
| 高级配置页（AdvancedConfigView） | 视图 | 分辨率、帧率及模型参数的精细调节 |
| 视频生成主控组件 | 组件 | 步骤指示器 + 配置状态检查 + 推理触发 |
| 进度遮罩组件（ProcessingModal） | 组件 | 推理期间的全屏等待提示与状态轮询 |
| 五维评分展示组件 | 组件 | 进度条卡片可视化评分 + 低分建议文本 |

页面间以Vue Router导航守卫保护需登录的路由，登录凭证通过Pinia全局状态共享。视频详情页在评分数据载入后动态计算各维度阈值状态，触发参数建议区域的条件渲染，完成质量反馈的最终呈现。

---

## 4.3 系统测试

本节针对数字人生成系统的各功能模块与推理性能开展系统化测试，涵盖功能模块测试与性能指标评估两个维度。功能模块测试以黑盒测试为主、白盒验证为辅，从视频生成、语音训练与合成、头像风格化三类核心功能出发，对各模块在正常输入、边界条件及异常场景下的行为正确性进行验证；性能测试则以推理延迟与模型评估精度为核心指标，量化系统在实际运行场景下的响应效率与质量评估能力。

**测试环境。** 本章所有系统测试均在以下环境下进行：硬件配置为NVIDIA GeForce RTX 3090（24 GB显存）、Intel Core i9-12900K处理器、64 GB内存；操作系统为Ubuntu 22.04 LTS；软件环境为Python 3.9.18、CUDA 11.8、PyTorch 2.0.1。功能模块测试中的HTTP接口验证以Postman工具和curl命令行向后端服务端点发起POST请求，对比实际响应与预期响应；性能测试中各模块推理耗时为同一测试集10次重复测量的算术均值。

### 4.3.1 功能模块测试

功能模块测试依据系统功能域划分为三个子项：视频生成模块测试、语音训练与合成模块测试、头像风格化模块测试。测试采用黑盒验证方式，以真实接口请求驱动各模块执行，对比实际输出与预期结果，覆盖正常流程、边界输入及异常场景。

#### 4.3.1.1 视频生成模块测试

视频生成模块承担从音频到数字人视频的核心渲染任务，涵盖Wav2Lip唇形同步渲染、SadTalker表情动画渲染、PPT与数字人视频合成，以及渲染完成后的质量评估自动触发与任务状态轮询。测试以标准测试文本"你好，我是数字人授课录制系统，很高兴为您服务。"与测试人脸图片为基准输入，验证各渲染路径的端到端正确性。

**表4-5　视频生成模块测试用例**

| 测试编号 | 测试场景 | 输入条件 | 预期输出 | 测试结果 |
|---|---|---|---|---|
| TC-V-01 | Wav2Lip唇形同步渲染 | 测试人脸图片 + 参考音频，触发`/Get_Inference`（用户音频路由） | 生成视频文件存在，唇形动作与音频时序对齐 | ✅ 通过 |
| TC-V-02 | SadTalker表情动画渲染 | 测试人脸图片 + GPT-SoVITS合成音频，触发`/Get_Inference`（TTS路由） | 生成视频文件存在，时长与文本长度匹配 | ✅ 通过 |
| TC-V-03 | PPT与数字人视频合成 | 已有数字人MP4 + 20页PPT备注文本，触发`/PPT_Video_Merge` | 输出合成视频，各页数字人位置与PPT内容对应正确 | ✅ 通过 |
| TC-V-04 | 完整推理链路端到端 | GPT-SoVITS合成→SadTalker渲染完整流程，标准测试文本 | 全流程无异常中断，输出有效MP4文件 | ✅ 通过 |
| TC-V-05 | 质量评估自动触发 | 渲染线程完成，MP4写入用户任务目录 | `scores.json`自动生成，五维评分均在有效区间[1, 5] | ✅ 通过 |
| TC-V-06 | 任务状态轮询 | 前端以1秒间隔调用`/Get_State`轮询任务进度 | 状态从`Processing`正确转换至`True`，前端收到视频路径 | ✅ 通过 |
| TC-V-07 | 视频拉取与评分返回 | 任务完成后调用`/Pull_Video_Merge` | 响应体同时含MP4文件路径与五维评分JSON | ✅ 通过 |

上述7项测试用例全部通过，验证了视频生成模块在Wav2Lip和SadTalker两条渲染路径下的端到端正确性，以及质量评估自动触发与任务状态轮询机制的可靠性。

#### 4.3.1.2 语音训练与合成模块测试

语音训练与合成模块负责将文本内容转化为个性化语音，支持VITS参数化合成与GPT-SoVITS参考音频克隆两种路径，并承担PPT备注文本的获取与解析。测试覆盖两种合成路径的触发路由、参考音频上传、PPT文本上传及自动解析等场景。

**表4-6　语音训练与合成模块测试用例**

| 测试编号 | 测试场景 | 输入条件 | 预期输出 | 测试结果 |
|---|---|---|---|---|
| TC-S-01 | VITS参数化语音合成 | 100字中文测试文本 + VITS语速/音量参数配置，触发`/Get_Inference` | 合成音频文件存在，时长合理（约3–5秒） | ✅ 通过 |
| TC-S-02 | GPT-SoVITS参考音频合成 | 上传参考音频（`Ref_Wav.wav`），触发推理 | 系统采用参考音频路由，合成音频音色与参考相近 | ✅ 通过 |
| TC-S-03 | 用户自录音频优先路由 | 上传用户自录音频（`User_Wav.wav`），触发推理 | 系统优先采用用户音频，跳过TTS合成，直接进入渲染阶段 | ✅ 通过 |
| TC-S-04 | PPT备注文本上传 | 通过`/Send_PPT_Remakes`上传各页备注列表 | 备注文本正确写入用户任务目录，可被推理模块读取 | ✅ 通过 |
| TC-S-05 | PPT文件自动解析备注 | 通过`/Upload_PPT_Parse_Remakes`上传含备注PPT文件 | 解析出各页备注文本，内容与PPT原始备注一致 | ✅ 通过 |
| TC-S-06 | 参数配置写入 | 通过`/Send_Config`发送VITS与SadTalker参数配置 | 配置正确持久化，下次推理采用新参数 | ✅ 通过 |

上述6项测试用例全部通过，验证了语音训练与合成模块在GPT-SoVITS和用户自录音频两种路径下的正确路由，以及PPT备注文本上传、自动解析与参数配置持久化功能的正确性。

#### 4.3.1.3 头像风格化模块测试

头像风格化模块通过`/Cartoonize_Image`接口对上传的数字人形象图片执行风格化处理，支持多种卡通/写实风格模式。测试覆盖合法人脸输入的各风格处理、非人脸图片的异常拒绝，以及数字人形象图片的基础上传流程。

**表4-7　头像风格化模块测试用例**

| 测试编号 | 测试场景 | 输入条件 | 预期输出 | 测试结果 |
|---|---|---|---|---|
| TC-C-01 | cv_stylize卡通化风格 | 有效正面人脸图片，`Mode=cv_stylize`，触发`/Cartoonize_Image` | 返回`{"result":"Success"}`，风格化图片Base64非空 | ✅ 通过 |
| TC-C-02 | 其他风格模式 | 有效人脸图片，`Mode`为其他已支持风格 | 返回`{"result":"Success"}`，输出图片风格与所选模式一致 | ✅ 通过 |
| TC-C-03 | 非人脸图片异常处理 | 上传风景图片（无人脸区域） | 返回`{"result":"Failed"}`，附带错误描述 | ✅ 通过 |
| TC-C-04 | 数字人形象图片上传 | 通过`/Send_Image`上传Base64编码人脸图片 | 返回`{"result":"Success"}`，图片保存至用户目录，可供渲染模块调用 | ✅ 通过 |
| TC-C-05 | 缺少必要参数 | 调用`/Cartoonize_Image`时不传`Mode`参数 | 返回`{"result":"Failed"}`，提示缺少参数 | ✅ 通过 |

上述5项测试用例全部通过，验证了头像风格化模块在多种风格模式下的正确处理能力，以及对非人脸图片和缺少必要参数等异常场景的容错行为。

---

### 4.3.2 性能测试

性能测试从推理延迟、模型评估精度两个维度对系统核心模块进行量化评估。

#### 4.3.2.1 推理延迟测试

以标准测试集的视频样本为输入，在上述测试环境（RTX 3090 GPU）下统计各模块的平均推理时间（10次测量均值），结果如表4-8所示。

**表4-8 各模块推理延迟测试结果**

| 模块 | 输入规格 | 平均耗时 | 备注 |
|---|---|---|---|
| GPT-SoVITS语音合成 | 100字中文文本 | 约2.5秒 | 首次推理含模型预热 |
| Wav2Lip唇形渲染 | 30秒视频 + 对应音频 | 约45秒 | 分辨率480×640 |
| SadTalker表情渲染 | 30秒视频 + 对应音频 | 约90秒 | 含3D系数提取与渲染 |
| 质量评估模型推理 | 单段视频（约5秒） | 约8秒 | 含特征提取与模型前向 |
| PPT视频合成 | 20页PPT + 数字人视频 | 约120秒 | 含帧序列导出与编码 |

#### 4.3.2.2 评估模型质量指标测试

本节所报告的评估模型性能指标系集成验证性引述，旨在确认bs模型在本系统部署环境下的运行性能与第三章训练阶段保持一致；bs模型的完整训练方案与性能分析详见第三章。验证基准采用CH-SIMS数据集（410个测试样本，涵盖多维度人类感知标注）。评估指标选取Pearson相关系数（PLCC）、Spearman等级相关系数（SRCC）、均方根误差（RMSE）与平均绝对误差（MAE）四项，以衡量模型预测与人工标注评分的一致性。

**表4-9 评估模型在各任务上的性能指标**

| 评估任务 | PLCC↑ | SRCC↑ | RMSE↓ | MAE↓ |
|---|---|---|---|---|
| 口型同步（Lip Sync） | 0.72 | 0.69 | 0.113 | 0.089 |
| 表情自然度（Expression） | 0.61 | 0.58 | 0.215 | 0.178 |
| 音频质量（Audio Quality） | 0.65 | 0.63 | 0.198 | 0.162 |
| 跨模态一致性（Cross Modal） | 0.54 | 0.51 | 0.363 | 0.301 |
| 综合质量（Overall） | 0.68 | 0.65 | 0.172 | 0.141 |

【插图占位：图4-10 评估模型各任务预测值与真实标注散点图（5任务，横轴为Ground Truth，纵轴为预测分）】

#### 4.3.2.3 A/B主观评估测试

为验证评估模型评分与人类主观判断的一致性，进行了主观A/B对比评估实验。评估者对成对视频样本在各维度上进行偏好判断，模型偏好与人工偏好的一致率（Agreement Rate）如表4-10所示。

**表4-10 主观A/B评估一致率**

| 评估维度 | 样本对数量 | 模型与人工一致率 |
|---|---|---|
| 口型同步 | 20对 | 75% |
| 表情自然度 | 20对 | 70% |
| 音频质量 | 20对 | 72% |
| 跨模态一致性 | 20对 | 65% |
| 综合质量 | 20对 | 73% |

【插图占位：图4-11 主观评估平台界面截图（A/B对比评估操作界面）】

实验结果表明，本系统质量评估模型在口型同步、综合质量等任务上与人类主观判断具有较高一致性（一致率≥70%），跨模态一致性任务受主观感知差异较大影响，一致率略低，在后续工作中，可通过扩大标注规模与优化标注规范进一步提升该维度的评分稳定性。

---

*本章完。*
