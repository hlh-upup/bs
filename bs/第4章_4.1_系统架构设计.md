## 4.1 系统架构设计

本章所实现的数字人智能授课视频生成系统旨在为教育工作者提供一站式的AI数字人教学视频制作平台。用户只需上传PPT课件与人像照片，系统即可自动完成语音合成、面部驱动、视频渲染与质量评价的全流程处理，最终输出具有真实说话效果的数字人教学视频。

### 4.1.1 整体架构概述

系统采用前后端分离的B/S（Browser/Server）架构，前端基于Vue 3框架构建单页面应用，后端以Python Flask框架为核心提供RESTful API服务。该架构设计具有以下主要优势：

（1）模块解耦。前后端各自独立开发与维护，前端专注于用户交互与界面渲染，后端专注于模型推理与业务逻辑，两者通过标准化接口通信，互不干扰。当某一模块需要升级或替换时，只要接口契约不变，另一端无需修改。

（2）独立部署与弹性扩展。前端静态资源构建完成后可部署于任意静态服务器，后端服务可根据GPU资源独立部署，必要时可进行水平扩展。两者通过HTTP协议通信，物理上可分布于不同服务器，为系统的灵活部署提供了便利条件。

（3）接口标准化。所有前后端通信均遵循RESTful风格的JSON接口规范，请求与响应格式统一，便于调试与维护，也为后续移动端或第三方系统接入预留了标准化通道。

根据功能职责的不同，系统整体被划分为三个核心模块：数字人视频生成模块、生成视频质量评价模块和前后端交互与可视化模块，三者协同构成完整的数字人教学视频制作管线。图4-1给出了系统的整体架构示意。

> **图4-1 系统整体架构图**

### 4.1.2 前端架构设计

前端采用Vue 3与TypeScript技术栈开发，使用Vite作为构建工具。Vue 3的组合式API使组件逻辑组织更为清晰，TypeScript提供了完备的类型安全保障，Vite则实现了快速的开发构建与热更新，显著提升了开发效率。

在状态管理方面，系统使用Pinia作为全局状态管理工具，分别维护用户认证状态与数字人业务状态两个独立的状态模块。前者负责用户登录态的维护与本地持久化，后者记录当前的处理进度、配置参数、已上传的素材文件以及各类生成选项等全局状态信息。

在页面路由方面，系统采用层级路由结构。顶层划分为登录页面与工作台主页面，工作台内部以嵌套路由形式组织了六个功能子页面，分别为系统首页、形象管理、视频生成配置、高级参数配置、语音训练和视频列表。系统设置了路由守卫机制，在每次页面跳转前自动检查用户认证状态，未登录用户将被重定向至登录页面。

在网络通信方面，前端封装了统一的接口服务层，对所有后端接口进行了集中管理，统一处理请求日志记录、响应错误捕获以及超时控制等公共逻辑，保持了网络层代码的规范性与可维护性。

### 4.1.3 后端架构设计

后端基于Python Flask框架构建，提供涵盖用户认证、素材上传、模型推理、状态查询、视频管理等功能在内的完整RESTful API服务，并启用跨域资源共享支持，确保前端可以从不同来源正常访问后端服务。

异步推理调度是后端的核心设计之一。由于数字人视频的生成涉及语音合成与面部驱动等深度学习模型推理，单次推理可能耗时数分钟，系统采用线程池机制来异步执行推理任务。当前端发起生成请求时，后端立即将推理任务提交至线程池并返回任务标识，前端随即进入轮询模式，周期性查询任务执行状态，直至任务完成或失败。这种异步调度机制避免了长时间的请求阻塞，有效提升了系统的并发响应能力。

在任务状态管理方面，系统为每个用户维护独立的状态记录，实时跟踪各项异步任务的执行进展。推理线程在任务开始前将状态标记为"进行中"，完成后更新为"成功"或"失败"，前端的轮询机制依赖此状态获取任务进度并向用户反馈。

在用户数据管理方面，系统为每个登录用户自动创建独立的数据目录结构，涵盖语音合成结果、面部驱动结果以及用户上传素材等子目录，确保多用户场景下数据相互隔离，不会产生干扰。

### 4.1.4 三大核心模块设计

**（1）数字人视频生成模块**

数字人视频生成模块是系统的核心功能模块，集成了语音合成引擎和面部驱动模型两大关键组件。语音合成方面，系统采用GPT-SoVITS模型，该模型支持少样本语音克隆，用户只需上传少量参考音频即可合成与目标说话人音色相近的语音。面部驱动方面，系统同时集成了SadTalker和Wav2Lip两种模型：SadTalker侧重于生成自然的头部运动与表情变化，适用于对表情自然度要求较高的场景；Wav2Lip则专注于精准的口型同步，能够将面部动作与音频实现高精度匹配。用户可在前端界面上根据实际需求灵活选择两种驱动模式。

此外，该模块支持两种音频输入方式：一是由系统根据PPT备注文本自动合成语音，二是用户直接上传自定义音频文件，以满足不同的使用场景需求。

**（2）生成视频质量评价模块**

生成视频质量评价模块在系统中承担在线质量评估职责。该模块集成了第三章所构建的多任务评价模型，在数字人视频生成完成后，系统自动调用评价模型对生成的视频进行多维度量化评分。评分结果包含总分、等级、各分项指标得分（口型同步、清晰度、时序稳定性、音频质量、表情自然度）、评测结论以及优化建议等信息，并通过前端界面反馈给用户。该模块使用户能够依据客观评分结果，有针对性地调整生成参数并重新生成，从而形成"生成—评估—建议—调整—再生成"的完整质量改进闭环，持续优化视频生成效果。

**（3）前后端交互与可视化模块**

前后端交互与可视化模块负责用户操作与后端处理之间的全链路打通。前端界面为用户提供了直观的操作入口：在形象管理页面上传人像照片并可选择进行风格化处理；在视频生成配置页面上传PPT课件、编辑各页备注文本、配置语音合成与面部驱动参数；在语音训练页面上传训练音频以定制个性化语音模型。

在视频生成过程中，前端通过轮询机制周期性查询后端任务进度，并在界面上向用户实时展示处理状态。任务完成后，生成的视频可在视频列表页面进行在线预览、下载或删除管理，质量评价结果同步以可视化形式呈现，包括总分、分项得分、等级标签与优化建议等要素，方便用户快速了解生成质量并做出后续决策。

### 4.1.5 系统工作流程

系统的完整工作流程如图4-2所示，主要包含以下六个步骤：

> **图4-2 系统工作流程图**

（1）用户登录与初始化。用户通过登录页面完成身份验证，系统在验证通过后自动为该用户创建独立的数据存储空间，并在前端保存登录状态。

（2）素材上传与参数配置。用户依次上传数字人人像照片、PPT课件等素材，系统自动解析PPT中的备注文本供用户编辑确认，同时用户可在配置面板中设置语音合成参数（如语速、情感风格）和面部驱动参数（如表情强度、分辨率、帧率）。

（3）视频生成推理。用户确认配置后启动视频生成，后端根据用户选择的驱动模式与音频来源，组装对应的推理管线并将任务提交至线程池异步执行。推理管线内部依次完成语音合成、音视频帧对齐、面部驱动渲染以及后处理与视频编码输出等步骤。

（4）状态轮询与实时反馈。推理任务执行期间，前端周期性地向后端查询任务状态，并在界面上实时展示处理进度，使用户能够随时了解当前生成任务的执行情况。

（5）质量评价与结果展示。视频生成完成后，系统自动调用质量评价模型对生成的视频进行多维度评分，评分结果与生成的视频一同呈现于前端。用户可观看视频、查看质量评价报告，并根据优化建议调整参数后重新生成，形成持续优化的闭环。

（6）视频管理与导出。用户可对已生成的视频进行在线预览、下载或删除操作。系统还支持将PPT与数字人视频合并导出，生成最终的完整教学视频。

综上所述，本系统以前后端分离的B/S架构为基础，通过数字人视频生成、质量评价和前后端交互三大核心模块的协同配合，实现了从素材输入到成品视频输出的全流程自动化处理，为教育工作者提供了高效、直观、闭环可控的数字人教学视频制作工具。
