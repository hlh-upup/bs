## 4.1 系统架构设计

本章所实现的数字人智能授课视频生成系统（以下简称"智课堂"系统）旨在为教育工作者提供一站式的AI数字人教学视频制作平台。用户只需上传PPT课件与人像照片，系统即可自动完成语音合成、面部驱动、视频渲染与质量评价的全流程处理，最终输出具有真实说话效果的数字人教学视频。

### 4.1.1 整体架构概述

系统采用前后端分离的B/S（Browser/Server）架构，前端基于Vue 3框架构建单页面应用（SPA），后端以Python Flask框架为核心提供RESTful API服务。该架构设计具有以下主要优势：

（1）**模块解耦**。前后端各自独立开发与维护，前端专注于用户交互与界面渲染，后端专注于模型推理与业务逻辑，互不干扰。当某一模块需要升级或替换时，只要接口契约不变，另一端无需修改。

（2）**独立部署与弹性扩展**。前端静态资源通过Vite构建后可部署于任意CDN或静态服务器，后端服务可根据GPU资源独立部署，必要时可水平扩展。两者通过HTTP协议通信，物理上可分布于不同服务器。

（3）**接口标准化**。所有前后端通信均遵循RESTful风格的JSON接口规范，请求与响应格式统一，便于调试与维护，也为后续移动端或第三方系统接入预留了标准化通道。

根据功能职责的不同，系统整体被划分为三个核心模块：**数字人视频生成模块**、**生成视频质量评价模块**和**前后端交互与可视化模块**，三者协同构成完整的数字人教学视频制作管线。图4-1给出了系统的整体架构示意。

> **图4-1 智课堂系统整体架构图**（示意）

### 4.1.2 前端架构设计

前端采用Vue 3 + TypeScript + Vite技术栈开发。Vue 3的Composition API使组件逻辑组织更为清晰，TypeScript提供了完备的类型检查，Vite作为新一代构建工具实现了极速的热模块替换（HMR），显著提升了开发效率。

**状态管理**方面，系统使用Pinia作为全局状态管理工具。系统定义了两个核心Store：`auth`（用户认证状态管理，负责登录态维护与本地持久化）和`digitalHuman`（数字人业务状态管理，记录当前处理进度、配置参数、上传文件及生成选项等全局状态）。Pinia相较于Vuex更轻量，且对TypeScript类型推导的支持更好。

**路由架构**方面，系统基于Vue Router实现了层级路由结构。顶层设有登录页面（`/login`）和工作台主页面（`/dashboard`），工作台内部以嵌套路由形式组织了六个功能子页面：首页（DashboardHome）、形象管理（PersonManagerView）、视频生成配置（VideoConfigView）、高级配置（AdvancedConfigView）、语音训练（VoiceTrainerView）和视频列表（VideoListView）。路由守卫（Navigation Guard）在每次页面跳转前检查用户认证状态，未登录用户将被自动重定向至登录页。

**接口服务层**方面，前端封装了一个统一的API服务类`DigitalHumanApiService`，基于Axios HTTP客户端实现。该服务类对所有后端API接口进行了封装，统一处理请求拦截（日志记录）、响应拦截（错误捕获）以及超时配置（普通请求1小时、文件上传2小时），并提供了调试开关支持。前端通过该服务类与后端进行全部交互，保持了网络层逻辑的集中管理。

### 4.1.3 后端架构设计

后端基于Python Flask框架构建，以`server1.4.0.py`为主入口文件，提供超过30个RESTful API端点，涵盖用户认证、数据上传、模型推理、状态查询、视频管理等全部业务功能。后端启用了Flask-CORS中间件以支持跨域请求，确保前端可以从不同域名或端口正常访问后端服务。

**异步推理调度机制**是后端的核心设计之一。由于数字人视频的生成涉及语音合成与面部驱动等深度学习模型推理，单次推理可能耗时数分钟，系统采用`concurrent.futures.ThreadPoolExecutor`线程池（最大5个工作线程）来异步执行推理任务。当前端发起推理请求（如`/Get_Inference`）时，后端立即将推理任务提交至线程池并返回任务标识，前端随即进入轮询模式，通过`/Get_State`接口周期性查询任务执行状态，直到任务完成或失败。这种异步调度机制避免了长时间的HTTP请求阻塞，有效提升了系统的并发响应能力。

**任务状态管理**采用基于JSON文件的轻量级方案。每个用户在服务端拥有独立的数据目录（`Data/{用户名}/`），目录下的`State.json`文件记录了该用户当前各项异步任务的执行状态（如`Processing`、`True`、`False`）。推理线程在任务执行前将状态写为"进行中"，完成后更新为"成功"或"失败"，前端的轮询机制正是依赖此状态文件获取任务进度。

**日志与异常处理**方面，后端配置了全局请求/响应日志（记录每次API调用的路径、参数、耗时与返回状态）、全局异常捕获（`@app.errorhandler`）以及推理端点专用的异常装饰器（`@log_exceptions`），确保系统在生产环境下具有完善的可观测性和容错能力。404错误处理中还额外输出了当前可用路由列表，方便开发调试。

**用户数据隔离**方面，系统通过`Create_File()`函数为每个登录用户自动创建独立的目录结构，包括VITS推理结果目录、SadTalker推理结果目录、Wav2Lip推理结果目录以及用户数据保存目录，确保多用户场景下数据不会互相干扰。用户上传的人像图片、PPT文件、训练音频以及生成的视频产物均存储于各自的隔离目录中。

### 4.1.4 三大核心模块设计

**（1）数字人视频生成模块**

数字人视频生成模块是系统的核心功能模块，集成了语音合成引擎和面部驱动模型两大关键组件。语音合成方面，系统采用GPT-SoVITS模型，该模型支持少样本（few-shot）语音克隆，用户只需上传少量参考音频即可合成与目标说话人音色相近的语音。面部驱动方面，系统同时集成了SadTalker和Wav2Lip两种模型——SadTalker侧重于生成自然的头部运动与表情变化，适用于对表情自然度要求较高的场景；Wav2Lip则专注于精准的口型同步，能够将驱动视频中的面部动作与音频实现高精度匹配。用户可在前端界面上通过"无动作模式（SadTalker）"和"有动作模式（Wav2Lip）"两种选项灵活选择。

该模块支持两种音频输入方式：一是由系统根据PPT备注文本自动合成语音（VITS模式），二是用户直接上传自定义音频文件（User Audio模式），以满足不同的使用场景需求。

**（2）生成视频质量评价模块**

生成视频质量评价模块在系统中承担在线质量评估职责。该模块集成了第三章所构建的多任务评价模型，在数字人视频渲染线程完成后，后端服务自动调用评价模型对生成的MP4视频进行多维度量化评分。评分结果包含总分、等级、分项指标（口型同步、清晰度、时序稳定性、音频质量、表情自然度）、评测结论、优化建议以及评测模式与时间等信息，并随即通过前端界面反馈给用户。该模块通过驱动参数优化建议，形成"生成—评估—建议—调整—再生成"的完整质量改进闭环，使用户能够依据客观评分结果持续优化视频生成效果。

评价服务以独立的Python脚本（`quality_eval_service.py`）形式实现，接收视频文件路径、模型检查点和配置文件三个参数，内部完成特征提取（视觉特征、音频特征、面部关键点特征、AU特征）、模型推理与评分汇总的全流程，输出结构化的JSON评分结果。

**（3）前后端交互与可视化模块**

前后端交互模块基于RESTful API实现用户操作与结果展示之间的全链路打通。前端界面提供了直观的操作入口：用户在形象管理页面上传人像照片并可选择进行二次元风格化处理（支持AnimeGANv2、WBC、OpenCV Stylization、Bilateral四种模式）；在视频生成配置页面上传PPT课件、编辑各页备注文本、配置语音与面部驱动参数；在语音训练页面上传训练音频以定制个性化语音模型。

前端在发起视频生成请求后进入轮询等待状态，以固定间隔（默认10秒）通过`/Get_State`接口查询任务进度，并通过全局模态框（ProcessingModal组件）向用户实时展示处理状态。任务完成后，生成的视频可在视频列表页面在线预览、下载或删除，质量评价结果则在同一界面以可视化方式呈现，包括总分、分项雷达图、等级标签与优化建议等要素。

### 4.1.5 系统工作流程

系统的完整工作流程如图4-2所示，具体步骤如下：

> **图4-2 智课堂系统工作流程图**（示意）

（1）**用户登录与初始化**。用户通过登录页面输入用户名与密码，后端验证通过后（`/Login`接口），自动为该用户创建数据隔离目录，并在前端保存登录状态。

（2）**素材上传与配置**。用户在形象管理页面上传数字人人像照片（`/Send_Image`接口），在视频生成配置页面上传PPT课件（`/Upload_PPT_Parse_Remakes`接口自动解析备注文本），编辑各页备注内容（`/Send_PPT_Remakes`接口），并在配置面板中设置语音合成参数（如语速、情感风格）和面部驱动参数（如表情强度、分辨率、帧率）（`/Send_Config`接口）。

（3）**视频生成推理**。用户点击"开始生成"后，前端调用推理接口（`/Get_Inference`），后端根据用户的配置选择对应的推理管线（VITS + SadTalker或User Audio + Wav2Lip），将推理任务提交至线程池异步执行。推理管线内部依次完成：语音合成（VITS/GPT-SoVITS）→ 音视频帧对齐 → 面部驱动渲染（SadTalker/Wav2Lip）→ 后处理与视频编码输出。

（4）**状态轮询与实时反馈**。推理任务执行期间，前端以10秒为间隔轮询任务状态（`/Get_State`接口），并在界面上实时展示处理进度。当状态返回"True"时表示生成完成，返回"Failed"时提示用户异常信息。

（5）**质量评价与结果展示**。视频生成完成后，后端自动调用质量评价模型对生成的视频进行多维度评分，评分结果与生成的视频一同返回前端。用户可在视频列表页面观看生成的视频，查看质量评价报告（含总分、等级、各分项指标得分、评测结论与优化建议），并根据建议调整参数后重新生成，形成持续优化的闭环。

（6）**视频管理与导出**。用户可对已生成的视频进行在线预览（`/Download_Merged_Video`接口）、批量下载或删除（`/Delete_Video`接口）操作。系统还支持PPT与数字人视频的合并导出（`/PPT_Video_Merge`系列接口），生成最终的完整教学视频。

综上所述，本系统以前后端分离的B/S架构为基础，通过数字人视频生成、质量评价和前后端交互三大核心模块的协同配合，实现了从素材输入到成品视频输出的全流程自动化处理，为教育工作者提供了高效、直观、闭环可控的数字人教学视频制作工具。
