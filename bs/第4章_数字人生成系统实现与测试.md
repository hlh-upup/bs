# 第4章 数字人生成系统实现与测试

## 4.1 系统架构设计

本章所实现的数字人智能授课视频生成系统旨在为教育工作者提供一站式的AI数字人教学视频制作平台。用户只需上传PPT课件与人像照片，系统即可自动完成语音合成、面部驱动、视频渲染与质量评价的全流程处理，最终输出具有真实说话效果的数字人教学视频。

### 4.1.1 整体架构概述

系统采用前后端分离的B/S（Browser/Server）架构，前端基于Vue 3框架构建单页面应用，后端以Python Flask框架为核心提供RESTful API服务。该架构设计具有以下主要优势：

（1）模块解耦。前后端各自独立开发与维护，前端专注于用户交互与界面渲染，后端专注于模型推理与业务逻辑，两者通过标准化接口通信，互不干扰。当某一模块需要升级或替换时，只要接口契约不变，另一端无需修改。

（2）独立部署与弹性扩展。前端静态资源构建完成后可部署于任意静态服务器，后端服务可根据GPU资源独立部署，必要时可进行水平扩展。两者通过HTTP协议通信，物理上可分布于不同服务器，为系统的灵活部署提供了便利条件。

（3）接口标准化。所有前后端通信均遵循RESTful风格的JSON接口规范，请求与响应格式统一，便于调试与维护，也为后续移动端或第三方系统接入预留了标准化通道。

根据功能职责的不同，系统整体被划分为三个核心模块：数字人视频生成模块、生成视频质量评价模块和前后端交互与可视化模块，三者协同构成完整的数字人教学视频制作管线。图4-1给出了系统的整体架构示意。

> **图4-1 系统整体架构图**

### 4.1.2 前端架构设计

前端采用Vue 3与TypeScript技术栈开发，使用Vite作为构建工具。Vue 3的组合式API使组件逻辑组织更为清晰，TypeScript提供了完备的类型安全保障，Vite则实现了快速的开发构建与热更新，显著提升了开发效率。

在状态管理方面，系统使用Pinia作为全局状态管理工具，分别维护用户认证状态与数字人业务状态两个独立的状态模块。前者负责用户登录态的维护与本地持久化，后者记录当前的处理进度、配置参数、已上传的素材文件以及各类生成选项等全局状态信息。

在页面路由方面，系统采用层级路由结构。顶层划分为登录页面与工作台主页面，工作台内部以嵌套路由形式组织了六个功能子页面，分别为系统首页、形象管理、视频生成配置、高级参数配置、语音训练和视频列表。系统设置了路由守卫机制，在每次页面跳转前自动检查用户认证状态，未登录用户将被重定向至登录页面。

在网络通信方面，前端封装了统一的接口服务层，对所有后端接口进行了集中管理，统一处理请求日志记录、响应错误捕获以及超时控制等公共逻辑，保持了网络层代码的规范性与可维护性。

### 4.1.3 后端架构设计

后端基于Python Flask框架构建，提供涵盖用户认证、素材上传、模型推理、状态查询、视频管理等功能在内的完整RESTful API服务，并启用跨域资源共享支持，确保前端可以从不同来源正常访问后端服务。

异步推理调度是后端的核心设计之一。由于数字人视频的生成涉及语音合成与面部驱动等深度学习模型推理，单次推理可能耗时数分钟，系统采用线程池机制来异步执行推理任务。当前端发起生成请求时，后端立即将推理任务提交至线程池并返回任务标识，前端随即进入轮询模式，周期性查询任务执行状态，直至任务完成或失败。这种异步调度机制避免了长时间的请求阻塞，有效提升了系统的并发响应能力。

在任务状态管理方面，系统为每个用户维护独立的状态记录，实时跟踪各项异步任务的执行进展。推理线程在任务开始前将状态标记为"进行中"，完成后更新为"成功"或"失败"，前端的轮询机制依赖此状态获取任务进度并向用户反馈。

在用户数据管理方面，系统为每个登录用户自动创建独立的数据目录结构，涵盖语音合成结果、面部驱动结果以及用户上传素材等子目录，确保多用户场景下数据相互隔离，不会产生干扰。

### 4.1.4 三大核心模块设计

**（1）数字人视频生成模块**

数字人视频生成模块是系统的核心功能模块，集成了语音合成引擎和面部驱动模型两大关键组件。语音合成方面，系统采用GPT-SoVITS模型，该模型支持少样本语音克隆，用户只需上传少量参考音频即可合成与目标说话人音色相近的语音。面部驱动方面，系统同时集成了SadTalker和Wav2Lip两种模型：SadTalker侧重于生成自然的头部运动与表情变化，适用于对表情自然度要求较高的场景；Wav2Lip则专注于精准的口型同步，能够将面部动作与音频实现高精度匹配。用户可在前端界面上根据实际需求灵活选择两种驱动模式。

此外，该模块支持两种音频输入方式：一是由系统根据PPT备注文本自动合成语音，二是用户直接上传自定义音频文件，以满足不同的使用场景需求。

**（2）生成视频质量评价模块**

生成视频质量评价模块在系统中承担在线质量评估职责。该模块集成了第三章所构建的多任务评价模型，在数字人视频生成完成后，系统自动调用评价模型对生成的视频进行多维度量化评分。评分结果包含总分、等级、各分项指标得分（口型同步、清晰度、时序稳定性、音频质量、表情自然度）、评测结论以及优化建议等信息，并通过前端界面反馈给用户。该模块使用户能够依据客观评分结果，有针对性地调整生成参数并重新生成，从而形成"生成—评估—建议—调整—再生成"的完整质量改进闭环，持续优化视频生成效果。

**（3）前后端交互与可视化模块**

前后端交互与可视化模块负责用户操作与后端处理之间的全链路打通。前端界面为用户提供了直观的操作入口：在形象管理页面上传人像照片并可选择进行风格化处理；在视频生成配置页面上传PPT课件、编辑各页备注文本、配置语音合成与面部驱动参数；在语音训练页面上传训练音频以定制个性化语音模型。

在视频生成过程中，前端通过轮询机制周期性查询后端任务进度，并在界面上向用户实时展示处理状态。任务完成后，生成的视频可在视频列表页面进行在线预览、下载或删除管理，质量评价结果同步以可视化形式呈现，包括总分、分项得分、等级标签与优化建议等要素，方便用户快速了解生成质量并做出后续决策。

### 4.1.5 系统工作流程

系统的完整工作流程如图4-2所示，主要包含以下六个步骤：

> **图4-2 系统工作流程图**

（1）用户登录与初始化。用户通过登录页面完成身份验证，系统在验证通过后自动为该用户创建独立的数据存储空间，并在前端保存登录状态。

（2）素材上传与参数配置。用户依次上传数字人人像照片、PPT课件等素材，系统自动解析PPT中的备注文本供用户编辑确认，同时用户可在配置面板中设置语音合成参数（如语速、情感风格）和面部驱动参数（如表情强度、分辨率、帧率）。

（3）视频生成推理。用户确认配置后启动视频生成，后端根据用户选择的驱动模式与音频来源，组装对应的推理管线并将任务提交至线程池异步执行。推理管线内部依次完成语音合成、音视频帧对齐、面部驱动渲染以及后处理与视频编码输出等步骤。

（4）状态轮询与实时反馈。推理任务执行期间，前端周期性地向后端查询任务状态，并在界面上实时展示处理进度，使用户能够随时了解当前生成任务的执行情况。

（5）质量评价与结果展示。视频生成完成后，系统自动调用质量评价模型对生成的视频进行多维度评分，评分结果与生成的视频一同呈现于前端。用户可观看视频、查看质量评价报告，并根据优化建议调整参数后重新生成，形成持续优化的闭环。

（6）视频管理与导出。用户可对已生成的视频进行在线预览、下载或删除操作。系统还支持将PPT与数字人视频合并导出，生成最终的完整教学视频。

综上所述，本系统以前后端分离的B/S架构为基础，通过数字人视频生成、质量评价和前后端交互三大核心模块的协同配合，实现了从素材输入到成品视频输出的全流程自动化处理，为教育工作者提供了高效、直观、闭环可控的数字人教学视频制作工具。

通过上述架构设计与工作流程的阐述，本系统的整体设计方案已清晰呈现。接下来将围绕三大核心模块，详细介绍各模块的具体实现过程与关键技术细节。

## 4.2 系统实现

本节围绕4.1节所划分的三大核心模块，分别从数字人视频生成、生成视频在线质量评价以及前后端交互实现三个方面，详细阐述系统各模块的具体实现过程与关键技术细节。

### 4.2.1 模型驱动数字人视频生成

数字人视频生成是本系统的核心功能，其完整流程涵盖课件文本提取、语音合成、面部驱动渲染、视频背景处理以及最终的课件视频合成等多个环节。本节将依次介绍各环节的实现方案。

**（1）课件文本提取与预处理**

系统支持用户上传PPT格式的课件文件，并自动从中提取各页幻灯片的备注文本作为语音合成的输入。文本提取采用两级策略：首先尝试通过Python的PPT解析库直接读取幻灯片的备注区域内容；若标准解析方式无法获取有效文本，系统将回退至对幻灯片中所有文本元素进行遍历扫描的方式。提取完成后，系统将各页备注文本以结构化形式返回前端，供用户进行二次编辑与确认。用户确认后的文本将作为后续语音合成的正式输入，确保生成内容与教学意图一致。

**（2）语音合成**

语音合成环节负责将课件备注文本转化为具有特定说话人音色的语音音频。系统采用GPT-SoVITS模型作为语音合成引擎，该模型融合了生成式预训练Transformer（GPT）与SoVITS（Soft Voice Token Integrated Synthesis）两种架构的优势，支持少样本（few-shot）语音克隆能力。

在使用流程上，用户只需上传一段时长约5秒的参考音频及其对应的文本标注，GPT-SoVITS模型即可从中学习目标说话人的声学特征，包括音色、韵律和语调风格等。随后，系统逐页读取课件备注文本，调用语音合成模型将文本转化为与参考说话人音色高度相似的语音音频。合成过程中，用户可通过参数配置控制语音的语速、采样温度、top-k与top-p等生成策略，以获得不同风格的合成效果。

此外，系统还支持个性化语音模型训练功能。用户可上传多段标注音频，系统将自动执行数据格式化、SoVITS模型微调与GPT模型微调的完整训练流程，生成专属于该用户的语音模型权重文件，供后续视频生成时使用。这一机制使得系统能够更精确地复现目标说话人的声学特征，显著提升合成语音的个性化程度与自然度。

除自动合成语音外，系统同时支持用户直接上传预录制的自定义音频文件。用户可将提前录制好的教学讲解音频按页上传至系统，跳过语音合成环节，直接进入面部驱动阶段。这种双通道音频输入设计为不同使用场景提供了灵活的适配方案。

**（3）面部驱动渲染**

面部驱动渲染环节是将静态人像照片转化为具有说话动态效果的视频的核心步骤。系统集成了SadTalker与Wav2Lip两种面部驱动模型，分别面向不同的应用需求。

SadTalker模型采用基于三维感知的生成框架，其核心思路是从输入音频中提取语音驱动信号，结合人像照片的面部三维形变系数，生成包含自然头部运动、面部表情变化与口型动作的说话人脸视频。该模型在推理时首先对输入人像进行面部区域裁剪与三维重建预处理，然后利用音频到运动系数的映射网络生成逐帧的三维运动参数，最后通过面部渲染器将运动参数映射回二维图像空间，输出完整的说话视频序列。

由于面部渲染器的初始输出分辨率较低，直接使用可能导致面部细节模糊、纹理失真等视觉质量问题，因此系统在渲染完成后引入了像素级面部增强与修复的后处理环节。该环节采用基于生成对抗网络的面部修复模型对渲染输出的每一帧进行逐帧处理，通过对面部区域进行超分辨率重建与纹理细节补全，将面部图像的分辨率提升至原始渲染输出的两倍，同时修复因三维重建与渲染过程中引入的面部伪影、模糊区域以及不自然的纹理过渡。系统提供了多种面部修复算法供用户选择，包括基于先验引导的面部复原算法、基于编码本查找的面部复原算法以及基于通道分裂注意力的面部增强算法，不同算法在细节保真度与生成自然度之间各有侧重，用户可根据具体场景需求灵活切换。此外，系统还支持可选的背景超分辨率增强功能，当用户启用该选项时，系统将在面部修复的同时对视频帧的背景区域进行二倍超分辨率重建，使整体画面品质得到全面提升。

SadTalker生成的视频经过上述面部增强后处理后，在面部清晰度与纹理真实感方面得到显著改善，具有较为自然的头部摆动和表情变化，适用于对表情丰富度与画面品质均有较高要求的教学视频场景。用户可通过参数面板调节表情强度、姿态幅度、面部增强算法类型、是否启用背景增强以及输出分辨率等参数。

Wav2Lip模型则专注于音频驱动的高精度口型同步。该模型基于卷积神经网络架构，以输入视频帧与对应音频片段为输入，通过唇形生成网络预测与音频时序精确匹配的口型区域像素，并将生成的口型区域无缝融合回原始视频帧中。在本系统中，Wav2Lip推理需要用户额外上传一段包含面部动作的驱动视频，系统首先将驱动视频的帧率统一调整至25帧/秒，然后根据各页音频时长对驱动视频进行分段裁剪，再逐段执行口型同步推理。Wav2Lip生成的视频在口型与音频的同步精度方面具有显著优势，特别适合对唇语准确性要求严格的应用场景。

两种模型的推理过程均以逐页为单位进行。系统根据课件页数与对应的语音音频文件，依次调用面部驱动模型生成各页的说话人脸视频片段，最终形成与课件页数一一对应的视频序列，为后续的视频合成环节提供素材。

**（4）视频背景处理与课件合成**

面部驱动渲染生成的视频片段通常包含固定的背景区域，为将数字人形象嵌入课件画面，系统需要对视频背景进行透明化处理。背景去除流程包括三个步骤：首先将视频逐帧拆解为静态图像序列；然后对每一帧调用背景分割算法，将人物主体从背景中分离并生成带透明通道的图像；最后将处理后的透明帧序列重新编码为支持Alpha通道的视频格式。

背景透明化完成后，系统进入课件视频合成阶段。合成过程以用户上传的PPT课件转换而成的基础视频为底层画面，按照各页语音的时间轴信息，将对应的透明背景数字人视频片段逐段叠加至课件画面的指定位置。系统支持三种合成模式：全页插入模式将数字人形象嵌入每一页课件画面；选择性插入模式允许用户指定需要嵌入数字人的特定页面；无插入模式则仅将语音音频与课件视频进行合并。

音频合成方面，系统按照课件页码顺序将各页语音音频文件依次拼接，在相邻页之间插入适当时长的静音段以实现自然过渡，最终将合成的完整音轨与课件视频进行音画同步合并，输出最终的数字人教学视频成品。

**（5）异步推理调度机制**

由于语音合成与面部驱动渲染均涉及深度学习模型推理，单次完整的视频生成流程可能耗时数分钟乃至更长时间。为避免长时间的请求阻塞影响系统响应能力，后端采用基于线程池的异步任务调度机制。当用户发起视频生成请求时，后端服务将推理任务提交至预置的线程池中异步执行，并立即向前端返回任务标识信息。推理线程在执行过程中实时更新任务状态记录，前端通过周期性状态查询获取任务进展，在任务完成后自动拉取生成结果。

系统根据用户上传的音频素材类型自动选择对应的推理管线。当检测到用户提供了参考音频与参考文本时，系统启动语音合成加SadTalker面部驱动的联合推理流程；当检测到用户上传了自定义音频文件时，系统则启动自定义音频加Wav2Lip口型同步的推理流程。无论采用何种管线，推理线程均在任务开始前将状态标记为"进行中"，在任务正常完成后标记为"成功"，在出现异常时标记为"失败"，确保前端能够准确获取任务的最终执行结果。

### 4.2.2 生成视频在线质量评价

生成视频在线质量评价模块负责在数字人视频生成完成后，自动对生成的视频进行多维度的量化质量评估，为用户提供客观的质量反馈与优化建议。该模块的核心是第三章所构建的多任务学习评价模型，本节将阐述该模型在系统中的集成方式与评价流程。

**（1）评价服务的调用时机与触发逻辑**

质量评价服务以独立进程的形式部署，在视频生成推理任务完成后由后端服务自动触发调用。具体而言，当推理线程将任务状态标记为"成功"后，后端服务随即启动质量评价流程，将生成的视频文件路径、评价模型检查点文件路径以及模型配置文件路径作为参数传入评价服务。评价服务在接收到调用请求后，自主完成从特征提取到模型推理再到评分汇总的完整评估流程，并将结构化的评分结果返回给后端服务，由后端服务转发至前端进行展示。

这种将评价服务与主推理流程解耦的设计具有两方面优势：一是评价模型的运行不会阻塞主推理线程，即使评价过程出现异常也不会影响已生成视频的正常使用；二是评价服务可以独立升级或替换为更先进的评价模型，而无需修改主推理流程的代码逻辑。

**（2）多模态特征提取**

评价服务首先对输入视频进行多模态特征提取，这是质量评分的基础环节。特征提取覆盖以下四个模态维度：

视觉特征方面，系统对视频帧进行逐帧采样，利用预训练的深度卷积神经网络提取每帧的高层视觉语义特征，捕捉画面清晰度、色彩保真度以及面部区域的视觉质量信息。

音频特征方面，系统从视频中分离音轨，基于预训练的语音表示模型提取音频的深层声学特征向量，涵盖音色、语调、节奏以及音频清晰度等声学维度的信息。

面部关键点特征方面，系统利用面部检测与关键点定位模型逐帧检测人脸区域，提取面部关键点的空间坐标序列，用于量化口型运动轨迹、面部表情动态以及头部姿态变化等几何层面的特征信息。

面部动作单元（AU）特征方面，系统基于面部动作编码系统提取各帧的动作单元激活强度，量化描述面部肌肉群的细粒度运动模式，为表情自然度与面部运动合理性的评估提供底层依据。

上述四类特征经过维度对齐与标准化处理后，形成多模态特征表示，作为评价模型的输入。

**（3）多任务评价模型推理**

多模态特征提取完成后，系统将四类特征输入第三章所构建的多任务学习评价模型进行推理。该模型采用共享编码器加任务特定预测头的架构，共享编码器基于Transformer结构对多模态特征进行深度融合与交叉注意力建模，学习音频、视觉、关键点与动作单元之间的跨模态关联表示；任务特定预测头则分别针对各评价维度输出独立的量化评分。

模型的评价输出包含以下分项指标：口型同步得分，衡量视频中口唇运动与音频内容的时序匹配精度；表情自然度得分，评估面部表情变化的合理性与流畅性；音频质量得分，反映合成语音的清晰度、自然度与音色保真程度；跨模态一致性得分，度量音频语义、视觉内容与面部动作之间的整体协调程度。此外，模型还输出一个综合评分，作为对视频整体感知质量的概括性度量。

各项评分均归一化至统一的数值区间，便于横向比较与等级划分。

**（4）评分结果汇总与优化建议生成**

模型推理完成后，评价服务对各项分数进行汇总处理，生成包含以下要素的结构化评分报告：综合总分与对应的质量等级标签、各分项指标的具体得分、基于各分项得分分析得出的评测结论，以及针对薄弱环节给出的参数优化建议。

优化建议的生成逻辑基于各分项得分的相对高低关系。当某一分项得分显著低于其他分项时，系统将该维度识别为当前视频的质量瓶颈，并据此推荐相应的参数调整策略。例如，当口型同步得分偏低时，建议用户尝试切换至口型同步精度更高的面部驱动模型或调整音频采样参数；当表情自然度得分不佳时，建议适当增大表情强度参数或使用表情表现力更强的驱动模型。

通过将评分结果与优化建议同步反馈给用户，系统构建了"生成—评估—建议—调整—再生成"的完整质量改进闭环。用户可根据评价报告有针对性地调整生成参数，并重新启动视频生成流程，从而持续优化视频的感知质量，直至达到满意效果。

### 4.2.3 前后端交互实现

前后端交互实现是连接用户操作与系统功能的桥梁，负责将用户的素材上传、参数配置等操作传递至后端处理，并将生成结果与评价反馈动态呈现于前端界面。本节将从素材上传与参数配置、异步任务状态管理、以及生成结果的展示与管理三个方面进行阐述。

**（1）素材上传与参数配置**

前端为用户提供了分步骤的素材上传与参数配置流程。在形象管理页面，用户上传用于生成数字人的人像照片，系统接收后将图片统一调整为模型所要求的尺寸规格并保存至用户的独立数据空间。该页面还提供了图像风格化功能，用户可选择将上传的真实人像转换为动漫风格或卡通风格，系统支持多种风格化算法，包括基于生成对抗网络的动漫风格迁移、白盒卡通化、以及基于图像滤波的风格化处理等，用户可根据偏好选择不同的风格化模式与参数。

在视频生成配置页面，用户上传PPT课件文件，系统自动完成课件解析与备注文本提取后，在页面上以可编辑列表的形式展示各页备注内容，供用户逐页审阅与修改。同一页面上还提供了语音合成与面部驱动的参数配置面板，用户可在此设置语速、采样策略、表情强度、输出分辨率、视频帧率、面部增强器等参数。用户还可选择使用系统预置的语音模型或此前训练的个性化语音模型。所有参数以结构化形式提交至后端，后端将参数写入用户独立的配置文件中，供推理阶段读取使用。

在语音训练页面，用户可上传多段带文本标注的训练音频，用于训练个性化语音合成模型。上传完成后，用户在界面上为每段音频标注对应的文本内容，确认后提交训练请求。后端接收到训练请求后，同样采用异步方式执行模型训练任务，训练完成后将模型权重保存至用户数据空间，供后续视频生成时调用。

**（2）异步任务状态管理与实时反馈**

由于视频生成与语音模型训练等核心任务均以异步方式执行，前后端之间需要建立可靠的任务状态同步机制。系统采用基于周期性状态查询的方案实现此功能。

当用户发起视频生成或模型训练等耗时操作后，后端将任务提交至异步执行队列并立即返回任务标识。前端在接收到任务标识后，以固定时间间隔（默认为10秒）周期性地向后端发送状态查询请求，获取当前任务的执行状态。后端为每个用户维护独立的任务状态记录，实时反映各项任务的执行进展，状态值包括"待执行""进行中""已完成"和"已失败"四种。

前端根据查询到的状态值执行相应的界面更新逻辑。当任务状态为"进行中"时，前端在界面上显示全局的处理进度提示框，告知用户当前正在执行的操作及预估等待时间，同时阻止用户发起新的重复操作；当状态转变为"已完成"时，前端自动关闭进度提示，加载并展示生成结果；当状态为"已失败"时，前端弹出错误提示信息，引导用户排查问题或重新提交任务。为防止网络异常导致的无限等待，系统设置了30分钟的最大轮询超时阈值，超时后自动终止查询并提示用户。

在全局状态管理层面，前端使用集中式状态管理方案维护两个核心状态模块。用户认证状态模块负责管理登录令牌的存储、校验与本地持久化，确保用户在刷新页面后仍能保持登录态；数字人业务状态模块则记录当前的处理进度、已上传的素材信息、生成参数配置、已选择的驱动模式以及各类异步任务的执行状态等全局信息，使各功能页面之间能够共享业务状态并保持数据一致性。

**（3）生成结果展示与视频管理**

视频生成任务完成后，用户可在视频列表页面查看与管理所有已生成的视频。该页面以列表形式展示每个视频的基本信息，包括文件名称、创建时间与视频时长等。用户可点击视频条目进行在线预览播放，无需将视频下载至本地；也可将视频下载至本地进行进一步编辑或分发；对于不再需要的视频，用户可执行删除操作释放存储空间。

在质量评价结果的展示方面，当视频对应的质量评分数据可用时，前端以可视化面板的形式呈现评价报告。面板中以数值与图形相结合的方式展示综合总分、质量等级标签以及各分项指标的具体得分，同时展示评测结论与优化建议文本，帮助用户直观理解视频的质量状况。用户可根据评价结果中指出的薄弱维度，回到参数配置页面调整相关生成参数，重新启动视频生成流程，实现迭代优化。

在用户数据隔离方面，系统为每个登录用户自动创建独立的数据目录结构，涵盖语音合成中间结果、面部驱动中间结果、用户上传素材、课件视频以及最终合成视频等子目录。所有文件读写操作均在用户各自的隔离空间内进行，确保多用户并发使用场景下数据互不干扰，保障了系统的数据安全性与多租户适用性。

通过上述各模块的具体实现，本系统已完整构建了从素材输入到视频生成、质量评价再到结果管理的全链路功能。为验证各模块的功能正确性与系统的整体协同运行表现，接下来将对系统进行系统化的功能测试。

## 4.3 系统测试

系统开发完成后，需要通过系统化的功能测试验证各模块是否按照预期设计正确运行。本节针对4.1节所划分的三大核心模块——数字人视频生成模块、生成视频质量评价模块以及前后端交互模块，分别设计并执行功能测试用例，展示各模块的测试过程与结果，最后从整体角度总结系统的协同运行表现。

### 4.3.1 模块功能测试

**（1）数字人视频生成模块测试**

数字人视频生成模块是系统的核心功能模块，其测试重点在于验证从课件文本输入到最终视频输出的完整生成管线是否能够正确、稳定地运行。测试围绕课件文本提取、语音合成、面部驱动渲染、视频背景处理与课件合成等关键环节逐一展开。

在课件文本提取环节的测试中，分别选取包含标准备注文本的PPT文件与不含备注的PPT文件作为测试输入。对于包含备注文本的课件，系统能够正确解析并提取各页幻灯片的备注内容，提取结果与PPT文件中的原始备注文本完全一致，各页文本以结构化列表的形式返回前端供用户审阅编辑。对于不含备注的课件，系统自动回退至全文本元素扫描策略，成功从幻灯片的标题、正文等文本元素中提取到可用文本，验证了两级文本提取策略的有效性与容错能力。

在语音合成环节的测试中，以一段时长约5秒的参考音频及其对应文本为输入，配合不同内容的课件备注文本，测试GPT-SoVITS模型的语音克隆与合成能力。测试结果表明，系统能够根据参考音频成功学习目标说话人的音色特征，并将课件备注文本逐页合成为与参考音色高度相似的语音音频文件。合成的语音在音色相似度、语句流畅度以及语调自然度方面均达到可用水平。同时测试了语速、采样温度等参数对合成结果的影响，调高语速参数后合成语音的语速明显加快，调节采样温度后语音的韵律变化程度随之改变，验证了参数配置对合成过程的有效控制能力。此外，还测试了自定义音频上传通道，用户直接上传的预录制音频文件能够被系统正确接收并跳过语音合成环节，直接进入面部驱动阶段，双通道音频输入机制工作正常。

在面部驱动渲染环节的测试中，分别对SadTalker与Wav2Lip两种驱动模型进行了功能验证。SadTalker模型测试中，以一张标准人像照片与合成的语音音频为输入，系统成功生成了包含自然头部运动与面部表情变化的说话视频。生成视频中人物的口型动作与音频内容基本同步，头部姿态呈现出自然的微幅摆动，面部表情随语音内容呈现合理的变化。进一步测试了像素级面部增强后处理功能，分别选择不同的面部修复算法执行增强处理，增强后的视频帧在面部清晰度与纹理细节方面较原始渲染输出有明显改善，面部伪影与模糊区域得到有效修复，验证了面部增强后处理环节的有效性。同时测试了表情强度、姿态幅度等参数的调节效果，增大表情强度参数后生成视频中人物的表情变化幅度相应增大，调节姿态幅度后头部运动的范围随之改变，各参数均能对生成结果产生符合预期的影响。

> **图4-3 SadTalker面部驱动渲染测试结果示例**

Wav2Lip模型测试中，以一段包含面部动作的驱动视频与对应的语音音频为输入，系统首先将驱动视频帧率统一调整至25帧/秒，然后按音频时长对视频进行分段裁剪，再逐段执行口型同步推理。测试结果显示，Wav2Lip生成的视频在口型与音频的同步精度方面表现优异，口唇运动与语音内容的时序匹配紧密，即使在快速语速条件下仍能保持较高的同步质量。

在视频背景处理与课件合成环节的测试中，验证了从视频背景透明化到课件视频合成的完整后处理流程。背景去除测试中，系统将面部驱动渲染生成的视频逐帧拆解后，对每帧执行背景分割处理，成功将人物主体从背景中分离并生成带透明通道的图像序列，透明化后的视频中人物边缘清晰，无明显分割残留。课件合成测试中，分别验证了三种合成模式的功能：全页插入模式下，数字人形象被正确嵌入每一页课件画面的指定位置；选择性插入模式下，仅用户指定的页面被嵌入数字人形象，其余页面保持原始课件画面；无插入模式下，系统仅将语音音轨与课件视频进行合并，输出不含数字人形象的教学视频。三种模式均能正确输出最终视频成品，音画同步效果良好。

> **图4-4 课件视频合成测试结果示例（三种合成模式）**

**（2）生成视频质量评价模块测试**

生成视频质量评价模块的测试旨在验证评价服务能否在视频生成完成后自动完成多维度质量评分，并输出准确、可靠的评价结果。

在评价服务触发与执行测试中，完成一次完整的视频生成流程后，观察评价服务是否被正确触发。测试结果表明，当推理线程将任务状态标记为"成功"后，后端服务在短时间内自动启动了质量评价流程，评价服务成功接收到生成视频的文件路径与模型配置参数，并完成了从特征提取到模型推理再到评分汇总的完整评估流程。评价过程未阻塞主推理线程，评价完成后结构化评分结果被正确返回至后端服务。同时测试了评价过程中的异常处理能力，当人为传入无效的视频文件路径时，评价服务能够捕获异常并返回错误信息，而不会导致系统崩溃或影响已生成视频的正常使用，验证了评价服务与主推理流程解耦设计的健壮性。

在多模态特征提取测试中，选取不同质量水平的生成视频作为输入，验证特征提取的覆盖度与准确性。测试结果显示，系统能够正确完成四个模态维度的特征提取：视觉特征方面，逐帧采样与深度卷积网络特征提取过程正常，输出的特征向量维度与预期一致；音频特征方面，音轨分离与声学特征提取正常运行，特征向量准确反映了音频的声学属性；面部关键点特征方面，面部检测与关键点定位模型成功定位各帧的人脸区域并提取关键点坐标序列；面部动作单元特征方面，各帧的动作单元激活强度被正确提取，特征维度与配置一致。四类特征经维度对齐与标准化后，形成的多模态特征表示能够被评价模型正确接收。

在评分输出验证测试中，对多段不同质量水平的生成视频执行质量评价，检验评分结果的合理性与区分度。测试结果表明，评价模型输出的各分项指标——口型同步得分、表情自然度得分、音频质量得分、跨模态一致性得分以及综合评分——均归一化至统一数值区间，数值范围符合预期。对于口型同步效果较好的视频，其口型同步得分明显高于同步效果较差的视频；对于面部表情变化自然流畅的视频，其表情自然度得分也相应较高。各分项得分能够合理反映视频在对应维度上的质量水平，综合评分则与各分项得分的整体趋势保持一致，验证了评价模型的区分能力与评分的合理性。

在优化建议生成测试中，验证系统能否根据评分结果自动生成有针对性的参数优化建议。测试中选取口型同步得分偏低但其他维度正常的视频，系统正确识别口型同步为当前质量瓶颈，并推荐用户尝试切换至口型同步精度更高的面部驱动模型或调整相关音频参数。选取表情自然度得分不佳的视频，系统建议适当增大表情强度参数或使用表情表现力更强的驱动模型。各类建议与对应的质量薄弱维度匹配准确，措辞清晰具有可操作性，能够有效引导用户进行下一轮参数调整。

> **图4-5 质量评价结果展示界面**

**（3）前后端交互模块测试**

前后端交互模块的测试覆盖用户认证、素材上传与参数配置、异步任务状态管理以及生成结果展示与管理等核心交互功能。

在用户认证功能测试中，分别使用正确与错误的用户凭据进行登录操作。输入正确的用户名与密码后，系统成功完成身份验证，前端页面跳转至工作台主界面，登录状态被正确保存至本地存储，刷新页面后用户仍保持登录态。输入错误凭据时，前端界面显示明确的错误提示信息，未发生页面跳转。测试路由守卫机制，未登录状态下直接访问工作台页面时，系统自动将请求重定向至登录页面，验证了认证保护机制的有效性。执行退出登录操作后，本地存储的认证信息被清除，再次访问工作台页面时被正确拦截并重定向至登录页面。

> **图4-6 用户登录界面测试**

在素材上传功能测试中，依次验证了人像照片上传、PPT课件上传以及训练音频上传等功能。人像照片上传测试中，通过形象管理页面的上传入口选择一张人像图片，系统正确接收图片并将其调整为模型要求的尺寸规格后保存至用户独立数据空间，上传完成后页面展示上传成功的反馈信息。同时测试了图像风格化功能，选择将真实人像转换为动漫风格后，系统调用风格化算法成功生成了动漫风格的人像图片，用户可在原始图像与风格化图像之间进行预览对比与切换选择。PPT课件上传测试中，上传一份包含多页幻灯片的PPT文件，系统自动完成解析并将各页备注文本以可编辑列表的形式展示于页面上，用户能够对提取的文本进行逐页编辑与确认。训练音频上传测试中，在语音训练页面上传多段WAV格式的音频文件，系统正确接收并显示各段音频的文件名与时长信息，用户可为每段音频标注对应文本内容。

> **图4-7 形象管理页面与图像风格化测试**

在参数配置功能测试中，验证了语音合成参数与面部驱动参数的配置流程。在视频生成配置页面上，用户可通过参数面板设置语速、采样策略、表情强度、输出分辨率、视频帧率以及面部增强算法类型等参数。测试中依次调整各项参数并提交配置，后端正确接收并将参数写入用户独立的配置文件中。随后启动视频生成，生成结果与配置参数的对应关系符合预期：调高语速后合成语音加快，增大表情强度后视频中人物表情变化更为明显，选择不同的面部增强算法后输出视频的面部清晰度与纹理风格产生相应差异。同时验证了驱动模式选择功能，在SadTalker与Wav2Lip两种模式之间切换后，系统能够正确启动对应的推理管线，输出与所选模式一致的生成结果。

在异步任务状态管理测试中，发起一次完整的视频生成任务，观察前后端之间的任务状态同步过程。任务提交后，后端立即返回任务标识，前端随即进入轮询模式，以固定时间间隔向后端发送状态查询请求。测试过程中监控了状态查询的请求日志，确认轮询间隔与预设值一致。在任务执行期间，前端界面显示全局处理进度提示框，包含当前正在执行的操作名称与进度百分比，同时页面上的重复操作按钮被禁用，防止用户重复提交。任务完成后，前端自动关闭进度提示并加载生成结果。此外，还测试了任务失败场景，当人为制造推理异常时，后端将任务状态标记为"失败"，前端在下一次轮询中检测到失败状态后弹出错误提示信息，引导用户排查问题。轮询超时保护机制同样通过测试验证，在超过设定的最大等待时间后，前端自动终止查询并向用户显示超时提示。

> **图4-8 视频生成过程中的进度反馈界面**

在生成结果展示与视频管理测试中，视频生成完成后进入视频列表页面，页面以卡片列表形式正确展示了所有已生成视频的基本信息，包括文件名称、创建时间与视频时长等。点击视频条目后，页面弹出视频播放器覆盖层，视频能够正常在线播放，画面与音频同步良好。执行视频下载操作后，浏览器成功下载视频文件至本地，文件完整性通过本地播放验证。执行视频删除操作后，系统弹出确认对话框，确认后视频从列表中移除，服务端文件同步删除，刷新页面后该视频不再出现于列表中。同时验证了质量评价结果的可视化展示功能，当视频对应的评分数据可用时，前端以可视化面板形式呈现了综合总分、质量等级标签、各分项指标得分、评测结论与优化建议等完整评价报告，展示效果清晰直观。

> **图4-9 视频列表页面与质量评价结果展示**

**（4）系统整体协同测试总结**

在完成各模块的独立功能测试后，对系统进行了端到端的完整流程测试，以验证三大核心模块在实际使用场景下的协同运行表现。

测试流程模拟了一次完整的数字人教学视频制作过程：首先登录系统并上传人像照片与PPT课件，完成参数配置后启动视频生成；系统依次执行语音合成、面部驱动渲染、视频背景处理与课件合成等环节，全程通过异步任务调度机制运行，前端实时展示处理进度；视频生成完成后，质量评价模块自动对生成视频进行多维度评分，评分结果与优化建议实时呈现于前端界面；根据评价报告中指出的薄弱维度，调整相关生成参数并重新启动视频生成流程，经过一轮参数优化后，新生成视频的评分在对应维度上有所提升，验证了"生成—评估—建议—调整—再生成"质量改进闭环的有效性。

此外，多用户并发测试表明，系统为每个登录用户维护的独立数据目录结构与任务状态记录能够有效隔离不同用户的数据与任务，两个用户同时发起视频生成请求时，各自的推理任务互不干扰，均能正常完成并输出正确结果，验证了系统在多用户并发场景下的数据隔离性与运行稳定性。

综合以上测试结果，数字人视频生成模块能够稳定完成从文本输入到视频输出的全流程处理，语音合成质量与面部驱动效果达到可用水平；生成视频质量评价模块能够自动完成多维度量化评分，评分结果合理可靠，优化建议具有针对性与可操作性；前后端交互模块实现了用户操作与系统功能之间的流畅衔接，异步任务管理机制运行稳定，生成结果的展示与管理功能完备。三大模块协同运行表现良好，系统整体具备稳定性、准确性与实用性，能够满足数字人教学视频自动化生成的实际应用需求，为后续的部署与推广奠定了坚实基础。
