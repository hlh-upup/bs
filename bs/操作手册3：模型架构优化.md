# ğŸ“‹ æ“ä½œæ‰‹å†Œ3ï¼šæ¨¡å‹æ¶æ„ä¼˜åŒ–

## ğŸ¯ åŸºäºå®é™…æ•°æ®ç»“æ„çš„ä¼˜åŒ–æ–¹æ¡ˆ

### ğŸ“Š å®é™…æ•°æ®ç»“æ„ç¡®è®¤
é€šè¿‡å®‰å…¨åˆ†æï¼Œæˆ‘ä»¬ç¡®è®¤äº†å‡†ç¡®çš„æ•°æ®ç»“æ„ï¼š

**æ•°æ®è§„æ¨¡**: 1,602ä¸ªæ ·æœ¬ (953è®­ç»ƒ + 239éªŒè¯ + 410æµ‹è¯•)
**ç‰¹å¾ç»´åº¦**:
- Visual: (batch, 150, 163) - 29,829ä¸ªNaNå€¼éœ€è¦å¤„ç†
- Audio: (batch, 150, 768)
- Keypoint: (batch, 150, 1404)
- AU: (batch, 150, 17)
- Syncnet: (batch, 2)
- Consistency: (batch, 1)

**æ ‡ç­¾èŒƒå›´**: [-0.8, 1.0]ï¼Œå­˜åœ¨-1.0çš„æ— æ•ˆæ ‡ç­¾

## ğŸš¨ å‘ç°çš„å…³é”®é—®é¢˜

### 1. æ•°æ®è´¨é‡é—®é¢˜
- **NaNå€¼**: Visualç‰¹å¾å­˜åœ¨29,829ä¸ªNaNå€¼
- **æ ‡ç­¾ç¼ºå¤±**: 27-30%çš„æ ‡ç­¾ä¸º-1.0ï¼ˆæ— æ•ˆå€¼ï¼‰
- **æ•°å€¼èŒƒå›´**: æ ‡ç­¾èŒƒå›´[-0.8, 1.0]ï¼Œéœ€è¦æ ‡å‡†åŒ–

### 2. ç‰¹å¾ç»´åº¦ä¸å¹³è¡¡
- **ç»´åº¦å·®å¼‚**: 163 vs 768 vs 1404 vs 17
- **å†—ä½™ç‰¹å¾**: Keypoint 1404ç»´å¯èƒ½åŒ…å«å†—ä½™ä¿¡æ¯

## ğŸ› ï¸ æ¨¡å‹æ¶æ„ä¼˜åŒ–æ–¹æ¡ˆ

### æ­¥éª¤1ï¼šåˆ›å»ºæ•°æ®é¢„å¤„ç†æ¨¡å‹

```bash
python -c "
import pickle
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from pathlib import Path

# åˆ›å»ºæ•°æ®å¤„ç†å™¨
class DataProcessor:
    def __init__(self):
        self.scalers = {}
        self.imputers = {}
        
    def process_data(self, data):
        '''å¤„ç†æ•°æ®ï¼šNaNå¤„ç† + æ ‡å‡†åŒ–'''
        processed = {}
        
        for split in ['train', 'val', 'test']:
            if split in data:
                print(f'å¤„ç† {split} æ•°æ®...')
                split_data = data[split]
                
                # æ”¶é›†ç‰¹å¾
                features = {}
                for key in ['visual', 'audio', 'keypoint', 'au', 'syncnet', 'consistency']:
                    if key in split_data[0]['features']:
                        feature_list = [s['features'][key] for s in split_data]
                        features[key] = np.array(feature_list)
                        
                        # NaNå¤„ç†
                        if key == 'visual':
                            # å¤„ç†Visualç‰¹å¾çš„NaNå€¼
                            reshaped = features[key].reshape(-1, features[key].shape[-1])
                            imputer = SimpleImputer(strategy='median')
                            imputed = imputer.fit_transform(reshaped)
                            features[key] = imputed.reshape(features[key].shape)
                            self.imputers[key] = imputer
                        
                        # æ ‡å‡†åŒ–
                        reshaped = features[key].reshape(-1, features[key].shape[-1])
                        scaler = StandardScaler()
                        scaled = scaler.fit_transform(reshaped)
                        features[key] = scaled.reshape(features[key].shape)
                        self.scalers[key] = scaler
                
                # å¤„ç†æ ‡ç­¾
                labels = {}
                valid_masks = {}
                for key in ['lip_sync_score', 'expression_score', 'audio_quality_score', 'cross_modal_score', 'overall_score']:
                    if key in split_data[0]['labels']:
                        label_list = [s['labels'][key] for s in split_data]
                        labels[key] = np.array(label_list)
                        
                        # åˆ›å»ºæœ‰æ•ˆæ ‡ç­¾æ©ç 
                        valid_masks[key] = labels[key] != -1.0
                        
                        # æ ‡å‡†åŒ–æœ‰æ•ˆæ ‡ç­¾åˆ°[0,1]èŒƒå›´
                        valid_labels = labels[key][valid_masks[key]]
                        if len(valid_labels) > 0:
                            min_val, max_val = valid_labels.min(), valid_labels.max()
                            labels[key][valid_masks[key]] = (valid_labels - min_val) / (max_val - min_val)
                
                processed[split] = {
                    'features': features,
                    'labels': labels,
                    'valid_masks': valid_masks
                }
        
        return processed

# æ‰§è¡Œå¤„ç†
data = pickle.load(open('datasets/ac.pkl', 'rb'))
processor = DataProcessor()
processed = processor.process_data(data)

# ä¿å­˜å¤„ç†ç»“æœ
with open('datasets/ac_final_processed.pkl', 'wb') as f:
    pickle.dump(processed, f)

print('âœ“ æ•°æ®å¤„ç†å®Œæˆ')
print('âœ“ å·²å¤„ç†NaNå€¼å’Œæ ‡å‡†åŒ–')
print('âœ“ å·²åˆ›å»ºæœ‰æ•ˆæ ‡ç­¾æ©ç ')
print('âœ“ åŸå§‹æ•°æ®å®Œå…¨æœªä¿®æ”¹')
"
```

### æ­¥éª¤2ï¼šåˆ›å»ºä¼˜åŒ–æ¨¡å‹æ¶æ„

```bash
python -c "
import torch
import torch.nn as nn
import numpy as np

class OptimizedMTLModel(nn.Module):
    def __init__(self, input_dims, hidden_dim=512, num_layers=6, num_heads=16, dropout=0.3):
        super().__init__()
        
        # ç‰¹å¾åµŒå…¥å±‚
        self.feature_embedders = nn.ModuleDict({
            'visual': nn.Sequential(
                nn.Linear(163, 256),
                nn.ReLU(),
                nn.Dropout(dropout),
                nn.Linear(256, hidden_dim)
            ),
            'audio': nn.Sequential(
                nn.Linear(768, 512),
                nn.ReLU(),
                nn.Dropout(dropout),
                nn.Linear(512, hidden_dim)
            ),
            'keypoint': nn.Sequential(
                nn.Linear(1404, 512),
                nn.ReLU(),
                nn.Dropout(dropout),
                nn.Linear(512, hidden_dim)
            ),
            'au': nn.Sequential(
                nn.Linear(17, 128),
                nn.ReLU(),
                nn.Dropout(dropout),
                nn.Linear(128, hidden_dim)
            ),
            'syncnet': nn.Sequential(
                nn.Linear(2, 128),
                nn.ReLU(),
                nn.Dropout(dropout),
                nn.Linear(128, hidden_dim)
            ),
            'consistency': nn.Sequential(
                nn.Linear(1, 128),
                nn.ReLU(),
                nn.Dropout(dropout),
                nn.Linear(128, hidden_dim)
            )
        })
        
        # æ—¶åºTransformer
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=hidden_dim,
            nhead=num_heads,
            dim_feedforward=hidden_dim * 4,
            dropout=dropout,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # ä»»åŠ¡ç‰¹å®šå¤´
        self.task_heads = nn.ModuleDict({
            'lip_sync': nn.Sequential(
                nn.Linear(hidden_dim, 256),
                nn.ReLU(),
                nn.Dropout(dropout),
                nn.Linear(256, 128),
                nn.ReLU(),
                nn.Linear(128, 1),
                nn.Sigmoid()  # è¾“å‡º[0,1]
            ),
            'expression': nn.Sequential(
                nn.Linear(hidden_dim, 256),
                nn.ReLU(),
                nn.Dropout(dropout),
                nn.Linear(256, 128),
                nn.ReLU(),
                nn.Linear(128, 1),
                nn.Sigmoid()
            ),
            'audio_quality': nn.Sequential(
                nn.Linear(hidden_dim, 256),
                nn.ReLU(),
                nn.Dropout(dropout),
                nn.Linear(256, 128),
                nn.ReLU(),
                nn.Linear(128, 1),
                nn.Sigmoid()
            ),
            'cross_modal': nn.Sequential(
                nn.Linear(hidden_dim, 256),
                nn.ReLU(),
                nn.Dropout(dropout),
                nn.Linear(256, 128),
                nn.ReLU(),
                nn.Linear(128, 1),
                nn.Sigmoid()
            ),
            'overall': nn.Sequential(
                nn.Linear(hidden_dim, 256),
                nn.ReLU(),
                nn.Dropout(dropout),
                nn.Linear(256, 128),
                nn.ReLU(),
                nn.Linear(128, 1),
                nn.Sigmoid()
            )
        })
        
        # ä»»åŠ¡æƒé‡
        self.task_weights = {
            'lip_sync': 0.8,
            'expression': 1.2,
            'audio_quality': 1.0,
            'cross_modal': 1.5,  # é‡ç‚¹ä¼˜åŒ–
            'overall': 1.3
        }
    
    def forward(self, features):
        # ç‰¹å¾åµŒå…¥
        embedded_features = []
        for key, embedder in self.feature_embedders.items():
            if key in features:
                # å¤„ç†æ—¶åºæ•°æ®
                batch_size, seq_len, feat_dim = features[key].shape
                x = features[key].reshape(-1, feat_dim)
                x = embedder(x)
                x = x.reshape(batch_size, seq_len, -1)
                embedded_features.append(x)
        
        # ç‰¹å¾èåˆ
        fused = torch.stack(embedded_features, dim=1).mean(dim=1)
        
        # Transformerå¤„ç†
        output = self.transformer(fused)
        
        # å…¨å±€å¹³å‡æ± åŒ–
        pooled = output.mean(dim=1)
        
        # å¤šä»»åŠ¡é¢„æµ‹
        predictions = {}
        for task, head in self.task_heads.items():
            predictions[task] = head(pooled).squeeze(-1)
        
        return predictions

# æµ‹è¯•æ¨¡å‹
model = OptimizedMTLModel({})
print('âœ“ ä¼˜åŒ–æ¨¡å‹æ¶æ„åˆ›å»ºå®Œæˆ')
print('âœ“ åŒ…å«NaNå¤„ç†ã€ç‰¹å¾æ ‡å‡†åŒ–ã€ä»»åŠ¡æƒé‡ä¼˜åŒ–')
print('âœ“ æ”¯æŒå¤šä»»åŠ¡å­¦ä¹ ')
print('âœ“ ä½¿ç”¨Transformeræ¶æ„')
"
```

### æ­¥éª¤3ï¼šåˆ›å»ºè®­ç»ƒä¼˜åŒ–å™¨

```bash
python -c "
import torch
import torch.nn as nn
from torch.optim import AdamW
from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts

class TrainingOptimizer:
    def __init__(self, model, task_weights):
        self.model = model
        self.task_weights = task_weights
        
        # ä¼˜åŒ–å™¨
        self.optimizer = AdamW(
            model.parameters(),
            lr=0.001,  # æå‡å­¦ä¹ ç‡
            weight_decay=0.01,
            betas=(0.9, 0.999)
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = CosineAnnealingWarmRestarts(
            self.optimizer,
            T_0=10,
            T_mult=2,
            eta_min=1e-6
        )
        
        # æŸå¤±å‡½æ•°
        self.criterion = nn.MSELoss(reduction='none')
    
    def compute_loss(self, predictions, targets, valid_masks):
        total_loss = 0
        losses = {}
        
        for task, pred in predictions.items():
            if task in targets and task in valid_masks:
                mask = valid_masks[task]
                if torch.any(mask):
                    target = targets[task]
                    loss = self.criterion(pred, target)
                    masked_loss = loss[mask]
                    task_loss = masked_loss.mean() * self.task_weights[task]
                    losses[task] = task_loss
                    total_loss += task_loss
        
        return total_loss, losses

# åˆ›å»ºä¼˜åŒ–å™¨
optimizer = TrainingOptimizer(None, {
    'lip_sync': 0.8,
    'expression': 1.2,
    'audio_quality': 1.0,
    'cross_modal': 1.5,
    'overall': 1.3
})

print('âœ“ è®­ç»ƒä¼˜åŒ–å™¨åˆ›å»ºå®Œæˆ')
print('âœ“ åŒ…å«AdamWä¼˜åŒ–å™¨')
print('âœ“ ä½¿ç”¨ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦')
print('âœ“ æ”¯æŒä»»åŠ¡æƒé‡å’Œæ©ç è®­ç»ƒ')
"
```

## ğŸ“Š ä¼˜åŒ–æ•ˆæœé¢„æœŸ

### é¢„æœŸæ€§èƒ½æå‡
- **RÂ²åˆ†æ•°**: ä»0.174æå‡è‡³0.45-0.65
- **Cross Modalä»»åŠ¡**: æå‡50-70%
- **è®­ç»ƒç¨³å®šæ€§**: NaNé—®é¢˜å®Œå…¨è§£å†³
- **æ”¶æ•›é€Ÿåº¦**: å‡å°‘40-60%è®­ç»ƒæ—¶é—´

### å†…å­˜å’Œè®¡ç®—ä¼˜åŒ–
- **æ‰¹æ¬¡å¤§å°**: ä»1æå‡è‡³4-8
- **ç‰¹å¾é™ç»´**: é€‰æ‹©æ€§é™ç»´å‡å°‘è®¡ç®—é‡
- **æ¢¯åº¦ç´¯ç§¯**: æœ‰æ•ˆæ‰¹æ¬¡å¤§å°è¾¾åˆ°32-64

## ğŸ¯ ä¸‹ä¸€æ­¥æ“ä½œ

### ç«‹å³æ‰§è¡Œ
```bash
# 1. æ•°æ®é¢„å¤„ç†
python -c "
# è¿è¡Œå®Œæ•´çš„æ•°æ®é¢„å¤„ç†
import pickle
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer

# åŠ è½½æ•°æ®
data = pickle.load(open('datasets/ac.pkl', 'rb'))

# é¢„å¤„ç†å‡½æ•°
def preprocess():
    processed = {}
    
    for split in ['train', 'val', 'test']:
        if split in data:
            split_data = data[split]
            
            # ç‰¹å¾å¤„ç†
            features = {}
            for key in ['visual', 'audio', 'keypoint', 'au']:
                feature_list = [s['features'][key] for s in split_data]
                features[key] = np.array(feature_list)
                
                # NaNå¤„ç†
                if key == 'visual':
                    reshaped = features[key].reshape(-1, features[key].shape[-1])
                    imputer = SimpleImputer(strategy='median')
                    imputed = imputer.fit_transform(reshaped)
                    features[key] = imputed.reshape(features[key].shape)
                
                # æ ‡å‡†åŒ–
                reshaped = features[key].reshape(-1, features[key].shape[-1])
                scaler = StandardScaler()
                scaled = scaler.fit_transform(reshaped)
                features[key] = scaled.reshape(features[key].shape)
            
            # æ ‡ç­¾å¤„ç†
            labels = {}
            valid_masks = {}
            for task in ['lip_sync_score', 'expression_score', 'audio_quality_score', 'cross_modal_score', 'overall_score']:
                label_list = [s['labels'][task] for s in split_data]
                labels[task] = np.array(label_list)
                valid_masks[task] = labels[task] != -1.0
            
            processed[split] = {'features': features, 'labels': labels, 'valid_masks': valid_masks}
    
    return processed

processed = preprocess()
with open('datasets/ac_final_processed.pkl', 'wb') as f:
    pickle.dump(processed, f)

print('âœ“ æ•°æ®é¢„å¤„ç†å®Œæˆï¼')
print('âœ“ æ–‡ä»¶ä¿å­˜åˆ°: datasets/ac_final_processed.pkl')
print('âœ“ åŸå§‹æ•°æ®å®Œå…¨ä¿ç•™')
"
```

---

**å½“å‰çŠ¶æ€**: âœ… å·²ç¡®è®¤å®é™…æ•°æ®ç»“æ„ï¼Œå‡†å¤‡æ‰§è¡Œä¼˜åŒ–è®­ç»ƒ