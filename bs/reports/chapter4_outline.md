# 第4章 说话人脸视频质量评估系统设计与实现

> **本章综述**：本章基于第3章提出的多模态多任务质量评估算法，围绕评估系统的工程化实现展开阐述。首先进行系统需求分析与总体架构设计，然后详细介绍后端API服务、前端可视化界面、数据库及模型推理服务的实现方案，最后通过系统化的测试与实验验证系统的正确性、有效性和可用性。

---

## 4.1 系统需求分析与总体设计

> **状态：待撰写**
>
> 预计内容：
> - **功能需求**：视频上传与管理、多模态特征提取与质量评估、多维度评分展示与可视化、数字人视频生成、PPT配音视频制作、用户认证与权限管理
> - **非功能需求**：单视频推理延时≤15秒、并发支持5用户、GPU显存≤8GB、系统可用性≥99%、前端响应时间≤200ms
> - **系统总体架构**：B/S架构，前端Vue.js 3 + 后端Flask + GPU推理服务 + 文件存储
> - **图表**：图4-x（系统总体架构图）

---

## 4.2 系统详细设计与实现

> **状态：待撰写**
>
> 预计内容：
> - **（1）后端API服务设计与实现**：Flask框架、RESTful接口设计（12个核心端点）、线程池异步推理、异常处理装饰器、CORS跨域、日志监控
> - **（2）前端可视化界面设计与实现**：Vue.js 3组件化架构、六大功能模块（登录、数字人管理、视频配置、生成、列表管理、语音训练）、Axios请求封装、路由守卫
> - **（3）模型推理服务设计与实现**：多模态特征提取管线（ResNet101/HuBERT/MediaPipe/AU）、PCA降维、Transformer融合推理、评分映射、混合精度推理
> - **（4）数据库与文件存储设计**：用户数据管理、视频文件组织、特征缓存、推理结果持久化
> - **图表**：图4-x（API接口设计图）、图4-x（前端页面交互流程图）、图4-x（模型推理流水线图）

---

## 4.3 系统测试与实验验证

> **状态：已完成** — 完整内容见 `chapter4_content.md`
>
> 本节通过五个方面全面验证系统的质量，包含以下内容：
> - **4.3.1 测试环境与配置**：表4-1（测试环境配置）、测试数据说明（EmotionTalk测试集199样本+20个额外测试视频）
> - **4.3.2 功能测试**：
>   - （1）后端API接口测试：12个端点、46个测试用例、100%通过率，表4-2
>   - （2）前端界面功能测试：6个模块、58个测试用例、100%通过率，表4-3
> - **4.3.3 模型集成测试**：
>   - （1）模型推理精度测试：五维度RMSE/MAE/R²/Pearson/Spearman/CCC，整体感知质量Pearson r=0.698，表4-4，图4-1
>   - （2）消融实验验证：9组消融配置，Transformer融合贡献20.5%为最大，表4-5，图4-2
>   - （3）评分一致性分析：Kendall τ/CCC/三分类准确率/QWK，整体QWK=0.668，表4-6
> - **4.3.4 系统性能测试**：
>   - （1）单视频推理延时：端到端12.02秒，特征提取占73.4%，表4-7，图4-3
>   - （2）并发处理能力：5并发内100%成功率，8并发降至87.5%，表4-8，图4-4
>   - （3）资源占用监控：CPU 45%、GPU 68%、内存4.2GB、显存2.1GB（单用户）
> - **4.3.5 用户主观评价实验**：
>   - （1）实验设计：被试内设计、12名参与者、30个分层抽样视频、5维度评分
>   - （2）评估者间一致性：ICC(2,1)和Krippendorff α，整体ICC=0.857，表4-9
>   - （3）模型vs主观评分对比：整体Pearson r=0.713、MAD=0.298分，表4-10，图4-5，图4-6
>   - （4）实验结论
> - **图表清单**：表4-1至表4-10（10张表）、图4-1至图4-6（6张图，含详细图示说明）

---

> **章节总结过渡**：本章通过系统需求分析、详细设计实现和全面的测试验证，构建了一个完整的说话人脸视频质量评估系统。系统测试结果表明，后端API和前端界面功能正确率达100%，模型在整体感知质量维度上达到0.698的Pearson相关系数，系统单视频推理延时为12.02秒，主观评价实验中模型评分与人工评分的相关性达到0.713，验证了系统的实用性与可靠性。
