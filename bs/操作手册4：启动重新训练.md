# ğŸ“‹ æ“ä½œæ‰‹å†Œ4ï¼šå¯åŠ¨é‡æ–°è®­ç»ƒ

## ğŸ¯ è®­ç»ƒå‡†å¤‡æ¸…å•

### âœ… å·²å®Œæˆå‡†å¤‡å·¥ä½œ

1. **æ•°æ®é¢„å¤„ç†å®Œæˆ**
   - âœ… NaNå€¼å¤„ç†å®Œæˆï¼ˆ29,829ä¸ªNaNå€¼å·²å¤„ç†ï¼‰
   - âœ… ç‰¹å¾æ ‡å‡†åŒ–å®Œæˆ
   - âœ… æ ‡ç­¾æ ‡å‡†åŒ–åˆ°[0,1]èŒƒå›´
   - âœ… æœ‰æ•ˆæ ‡ç­¾æ©ç åˆ›å»ºå®Œæˆ
   - âœ… å¤„ç†åçš„æ•°æ®ï¼š`datasets/ac_final_processed.pkl`

2. **æ¨¡å‹æ¶æ„ä¼˜åŒ–å®Œæˆ**
   - âœ… Transformerå±‚æ•°ï¼š6å±‚ï¼ˆä»3å±‚æå‡ï¼‰
   - âœ… æ³¨æ„åŠ›å¤´æ•°ï¼š16å¤´ï¼ˆä»8å¤´æå‡ï¼‰
   - âœ… éšè—å±‚ç»´åº¦ï¼š512ç»´ï¼ˆä»256ç»´æå‡ï¼‰
   - âœ… ä»»åŠ¡æƒé‡ä¼˜åŒ–ï¼šCross Modalæƒé‡1.5ï¼ˆé‡ç‚¹ä¼˜åŒ–ï¼‰

3. **è®­ç»ƒé…ç½®ä¼˜åŒ–å®Œæˆ**
   - âœ… å­¦ä¹ ç‡ï¼š0.001ï¼ˆä»0.0001æå‡ï¼‰
   - âœ… æ‰¹æ¬¡å¤§å°ï¼š4ï¼ˆä»1æå‡ï¼Œé…åˆæ¢¯åº¦ç´¯ç§¯ï¼‰
   - âœ… ä¼˜åŒ–å™¨ï¼šAdamWï¼ˆä»Adamå‡çº§ï¼‰
   - âœ… å­¦ä¹ ç‡è°ƒåº¦ï¼šä½™å¼¦é€€ç«+é¢„çƒ­
   - âœ… æ¢¯åº¦è£å‰ªï¼šé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸

## ğŸš€ å¯åŠ¨è®­ç»ƒ

### æ­¥éª¤1ï¼šéªŒè¯ç¯å¢ƒ

```bash
# 1. æ£€æŸ¥å¤„ç†åçš„æ•°æ®
python -c "
import pickle
import torch
from pathlib import Path

# æ£€æŸ¥æ•°æ®æ–‡ä»¶
if Path('datasets/ac_final_processed.pkl').exists():
    with open('datasets/ac_final_processed.pkl', 'rb') as f:
        data = pickle.load(f)
    
    print('=== æ•°æ®éªŒè¯ ===')
    for split in ['train', 'val', 'test']:
        if split in data:
            print(f'{split}: {len(data[split][\"labels\"][\"lip_sync_score\"])} samples')
            for key in data[split][\"features\"].keys():
                print(f'  {key}: {data[split][\"features\"][key].shape}')
    print('âœ“ æ•°æ®éªŒè¯é€šè¿‡')
else:
    print('âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨')
"
```

### æ­¥éª¤2ï¼šå¯åŠ¨è®­ç»ƒ

```bash
# å¯åŠ¨å®Œæ•´è®­ç»ƒ
python train_optimized.py \
    --data_path datasets/ac_final_processed.pkl \
    --output_dir experiments/optimized_run1 \
    --batch_size 4 \
    --epochs 150 \
    --lr 0.001
```

### æ­¥éª¤3ï¼šç›‘æ§è®­ç»ƒ

#### å®æ—¶ç›‘æ§è„šæœ¬
```bash
# åˆ›å»ºç›‘æ§è„šæœ¬
python -c "
import os
import time
import pickle
from pathlib import Path

def monitor_training():
    log_file = 'experiments/optimized_run1/training.log'
    
    if os.path.exists(log_file):
        with open(log_file, 'r') as f:
            lines = f.readlines()
            
        print('=== è®­ç»ƒç›‘æ§ ===')
        for line in lines[-5:]:
            print(line.strip())
    else:
        print('ç›‘æ§æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨')

# å®æ—¶ç›‘æ§
monitor_training()
"
```

## ğŸ“Š è®­ç»ƒç›‘æ§å·¥å…·

### åˆ›å»ºè®­ç»ƒç›‘æ§è„šæœ¬

```bash
python -c "
# åˆ›å»ºè®­ç»ƒç›‘æ§å™¨
with open('scripts/monitor_training.py', 'w') as f:
    f.write('''
#!/usr/bin/env python
import pickle
import matplotlib.pyplot as plt
import pandas as pd
from pathlib import Path
import time

class TrainingMonitor:
    def __init__(self, log_dir):
        self.log_dir = Path(log_dir)
        
    def load_history(self):
        history_file = self.log_dir / 'training_history.pkl'
        if history_file.exists():
            with open(history_file, 'rb') as f:
                return pickle.load(f)
        return None
    
    def plot_training_curves(self):
        history = self.load_history()
        if not history:
            print('è®­ç»ƒå†å²æ–‡ä»¶ä¸å­˜åœ¨')
            return
        
        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # æŸå¤±æ›²çº¿
        axes[0,0].plot(history['train_loss'], label='Train Loss')
        axes[0,0].plot(history['val_loss'], label='Val Loss')
        axes[0,0].set_title('Training Loss')
        axes[0,0].set_xlabel('Epoch')
        axes[0,0].set_ylabel('Loss')
        axes[0,0].legend()
        axes[0,0].grid(True)
        
        # RÂ²åˆ†æ•°è¶‹åŠ¿
        if history['val_metrics']:
            tasks = list(history['val_metrics'][0].keys())
            for task in tasks:
                r2_scores = [m[task]['r2'] for m in history['val_metrics'] if task in m]
                axes[0,1].plot(r2_scores, label=task)
            
            axes[0,1].set_title('Validation RÂ² Scores')
            axes[0,1].set_xlabel('Epoch')
            axes[0,1].set_ylabel('RÂ²')
            axes[0,1].legend()
            axes[0,1].grid(True)
        
        # ä¿å­˜å›¾è¡¨
        plt.tight_layout()
        plt.savefig(self.log_dir / 'training_curves.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print('âœ“ è®­ç»ƒå›¾è¡¨å·²ç”Ÿæˆ')
    
    def print_summary(self):
        history = self.load_history()
        if not history:
            return
        
        print('=== è®­ç»ƒæ‘˜è¦ ===')
        print(f'æ€»è®­ç»ƒè½®æ•°: {len(history[\"train_loss\"])}')
        print(f'æœ€ä½³éªŒè¯æŸå¤±: {min(history[\"val_loss\"]):.4f}')
        
        if history['val_metrics']:
            latest_metrics = history['val_metrics'][-1]
            print('æœ€ç»ˆéªŒè¯æŒ‡æ ‡:')
            for task, metrics in latest_metrics.items():
                print(f'  {task}: RÂ²={metrics[\"r2\"]:.3f}, RMSE={metrics[\"rmse\"]:.3f}')

if __name__ == \"__main__\":
    monitor = TrainingMonitor('experiments/optimized_run1')
    monitor.print_summary()
    monitor.plot_training_curves()
''')

print('âœ“ è®­ç»ƒç›‘æ§å™¨å·²åˆ›å»º: scripts/monitor_training.py')
"
```

## ğŸ”„ è®­ç»ƒä¸­æ–­ä¸æ¢å¤

### ä¸­æ–­åç»§ç»­è®­ç»ƒ
```bash
# æ£€æŸ¥æ£€æŸ¥ç‚¹
ls -la experiments/optimized_run1/checkpoint_*.pth

# ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
python train_optimized.py \
    --data_path datasets/ac_final_processed.pkl \
    --output_dir experiments/optimized_run1_resume \
    --batch_size 4 \
    --epochs 150 \
    --lr 0.001
```

### å¿«é€Ÿæµ‹è¯•è®­ç»ƒ
```bash
# å¿«é€ŸéªŒè¯ï¼ˆ10ä¸ªepochï¼‰
python train_optimized.py \
    --data_path datasets/ac_final_processed.pkl \
    --output_dir experiments/quick_test \
    --batch_size 4 \
    --epochs 10 \
    --lr 0.001
```

## ğŸ“ˆ é¢„æœŸè®­ç»ƒæ—¶é—´

### åŸºäºç¡¬ä»¶é…ç½®
- **16GB GPU**: é¢„è®¡æ¯ä¸ªepoch 15-25åˆ†é’Ÿ
- **æ€»è®­ç»ƒæ—¶é—´**: 150 epochs Ã— 20åˆ†é’Ÿ = çº¦50å°æ—¶
- **ç›‘æ§å»ºè®®**: æ¯10ä¸ªepochæ£€æŸ¥ä¸€æ¬¡è¿›åº¦

### æ€§èƒ½åŸºå‡†
- **ç›®æ ‡RÂ²**: 0.45-0.65ï¼ˆä»0.174æå‡ï¼‰
- **Cross Modalæå‡**: 50-70%
- **è®­ç»ƒç¨³å®šæ€§**: æ¶ˆé™¤NaNå€¼é—®é¢˜

## âš¡ å¿«é€Ÿå¯åŠ¨ï¼ˆæ¨èï¼‰

### ä¸€é”®å¯åŠ¨è„šæœ¬
```bash
# åˆ›å»ºå¯åŠ¨è„šæœ¬
python -c "
with open('start_training.sh', 'w') as f:
    f.write('''#!/bin/bash

echo \"=== å¯åŠ¨ä¼˜åŒ–è®­ç»ƒ ===\"

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p experiments/optimized_run1/logs

# å¯åŠ¨è®­ç»ƒ
python train_optimized.py \
    --data_path datasets/ac_final_processed.pkl \
    --output_dir experiments/optimized_run1 \
    --batch_size 4 \
    --epochs 150 \
    --lr 0.001 \
    --device cuda 2>&1 | tee experiments/optimized_run1/training.log

echo \"=== è®­ç»ƒå®Œæˆ ===\"
echo \"æŸ¥çœ‹ç»“æœ: python scripts/monitor_training.py\"
''')

import os
os.chmod('start_training.sh', 0o755)
print('âœ“ å¯åŠ¨è„šæœ¬å·²åˆ›å»º: start_training.sh')
"
```

### æ‰§è¡Œä¸€é”®å¯åŠ¨
```bash
# å¼€å§‹è®­ç»ƒ
./start_training.sh
```

## ğŸ“ ç›‘æ§å’Œè°ƒè¯•

### å®æ—¶ç›‘æ§
```bash
# åœ¨å¦ä¸€ä¸ªç»ˆç«¯çª—å£æ‰§è¡Œ
tail -f experiments/optimized_run1/training.log

# æˆ–ä½¿ç”¨watchå‘½ä»¤
watch -n 60 'python scripts/monitor_training.py'
```

### å¸¸è§é—®é¢˜å¤„ç†

#### é—®é¢˜1ï¼šæ˜¾å­˜ä¸è¶³
```bash
# å‡å°‘æ‰¹æ¬¡å¤§å°
python train_optimized.py --batch_size 2 --epochs 150
```

#### é—®é¢˜2ï¼šè®­ç»ƒé€Ÿåº¦æ…¢
```bash
# é™ä½æ¨¡å‹å¤æ‚åº¦
python train_optimized.py --batch_size 4 --epochs 100
```

#### é—®é¢˜3ï¼šè¿‡æ‹Ÿåˆ
```bash
# å¢åŠ æ­£åˆ™åŒ–
python train_optimized.py --batch_size 4 --epochs 150 --dropout 0.5
```

---

## ğŸ¯ æœ€ç»ˆæ‰§è¡ŒæŒ‡ä»¤

**ç«‹å³æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å¼€å§‹è®­ç»ƒï¼š**

```bash
# 1. éªŒè¯æ•°æ®
python -c "import pickle; d = pickle.load(open('datasets/ac_final_processed.pkl', 'rb')); print('æ•°æ®éªŒè¯é€šè¿‡')"

# 2. å¯åŠ¨è®­ç»ƒ
python train_optimized.py --data_path datasets/ac_final_processed.pkl --output_dir experiments/optimized_run1 --batch_size 4 --epochs 150 --lr 0.001

# 3. ç›‘æ§è®­ç»ƒï¼ˆåœ¨å¦ä¸€ä¸ªç»ˆç«¯ï¼‰
python scripts/monitor_training.py
```

**é¢„è®¡å®Œæˆæ—¶é—´ï¼š50å°æ—¶**  
**é¢„æœŸæ€§èƒ½æå‡ï¼šRÂ²ä»0.174æå‡è‡³0.45-0.65**